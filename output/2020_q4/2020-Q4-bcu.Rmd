---
params:
  bcu: "North West"
header-includes:
  - \usepackage[onehalfspacing]{setspace}
  - \usepackage[scaled]{helvet}
  - \usepackage[T1]{fontenc}
  - \usepackage{xcolor}
  - \definecolor{uclyellow}{HTML}{F6BE00}
  - \usepackage{titlesec}
  - \titleformat{\section}{\bigskip\raggedright\LARGE\sffamily}{\thesection}{0.5em}{}[\titlerule]
  - \usepackage[absolute]{textpos}
  - \setlength{\TPHorizModule}{1cm}
  - \setlength{\TPVertModule}{\TPHorizModule}
  - \textblockorigin{0cm}{0cm}
  - \usepackage{float}
  - \usepackage{booktabs}
  - \hypersetup{colorlinks=true, linkcolor=blue, filecolor=blue, urlcolor=blue, pdftitle={Stop and search in London}, bookmarks=true}
output: 
  bookdown::pdf_document2:
    latex_engine: xelatex
    includes:
      in_header: "preamble.tex"
      before-body: "before-body.tex"
    keep_tex: true
    number_sections: false
    toc: false
papersize: a4
classoption: "twoside, 11pt"
geometry: "top=2cm, outer=3.5cm, bottom=3cm, inner=3.5cm"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(cache = TRUE, echo = FALSE, fig.align = "center", fig.pos = 'tb')

library("assertthat")
library(bookdown)
library("fable")
library("feasts")
library("ggrepel")
library("ggtext")
library("janitor")
library("lubridate")
library("magick")
library("scales")
library("sf")
library(SpatialKDE)
library(spdep)
library("tsibble")
library("tidyverse")
```



```{r functions}
source(here::here("../helpers.R"))

# define colour scheme, based on the UCL colour scheme defined at
# https://www.ucl.ac.uk/cam/brand/guidelines/colour
ucl_colours <- tribble(
  ~name, ~hex_code,
  "Dark Green", "#555025",
  "Dark Red", "#651D32",
  "Dark Purple", "#4B384C",
  "Dark Blue", "#003D4C",
  "Dark Brown", "#4E3629",
  "Mid Green", "#8F993E",
  "Mid Red", "#93272C",
  "Mid Purple", "#500778",
  "Mid Blue", "#002855",
  "Stone", "#D6D2C4",
  "Bright Green", "#B5BD00",
  "Bright Red", "#D50032",
  "Bright Blue", "#0097A9",
  "Bright Pink", "#AC145A",
  "Light Green", "#BBC592",
  "Light Red", "#E03C31",
  "Light Purple", "#C6B0BC",
  "Light Blue", "#8DB9CA",
  "Yellow", "#F6BE00",
  "Orange", "#EA7600",
  "Grey", "#8C8279",
  "Blue Celeste", "#A4DBE8"
)

ucl_colours_list <- set_names(ucl_colours$hex_code, ucl_colours$name)

search_type_colours <- c(
  "drugs" = ucl_colours_list[["Bright Green"]], 
  "weapons" = ucl_colours_list[["Light Purple"]], 
  "stolen goods" = ucl_colours_list[["Bright Blue"]], 
  "firearms" = ucl_colours_list[["Bright Red"]], 
  "other" = ucl_colours_list[["Blue Celeste"]], 
  "unknown" = ucl_colours_list[["Grey"]],
  "weapons (based on reasonable suspicion)" = ucl_colours_list[["Bright Pink"]],
  "weapons (based on authorisation)" = ucl_colours_list[["Light Red"]]
)

to_text <- partial(knitr::combine_words, oxford_comma = FALSE)

prop_of_total <- function (data, var, criteria, filter = TRUE) {
  stops %>% 
    dplyr::filter(date >= date_start, {{filter}}) %>% 
    dplyr::count({{var}}) %>% 
    janitor::adorn_percentages(denominator = "col") %>% 
    dplyr::filter({{criteria}}) %>% 
    purrr::pluck("n")
}

compare_props <- function (prop_a, prop_b) {
  abs_diff <- abs(prop_a - prop_b)
  direction <- ifelse(prop_a > prop_b, "higher", "lower")
  case_when(
    abs_diff > 0.05 ~ str_glue("{direction} than"),
    abs_diff > 0.025 ~ str_glue("slightly {direction} than"),
    abs_diff > 0.01 ~ str_glue("marginally {direction} than"),
    TRUE ~ "about the same as"
  )
}

mid_point <- function (a, b) {
  if (a > b) {
    b + ((a - b) / 2)
  } else {
    a + ((b - a) / 2)
  }
}

theme_stop_search <- function (...) {
  theme_minimal(...) %+replace%
    theme(
      axis.ticks = element_line(colour = "grey92"),
      axis.title = element_text(size = 9, hjust = 1),
      legend.key.height = unit(4, "mm"),
      legend.key.width = unit(6, "mm"),
      legend.position = "bottom",
      legend.spacing.x = unit(2, "mm"),
      legend.title = element_text(size = 9),
      panel.grid.major.x = element_blank(),
      panel.grid.minor.x = element_blank(),
      plot.caption = element_text(size = 9, colour = "grey33", hjust = 1, 
                                  margin = margin(t = 3)),
      plot.margin = margin(t = 0, b = 9),
      plot.tag = element_text(size = 12, face = "bold", colour = "grey33", 
                              hjust = 0),
      plot.tag.position = c(0.01, 0.01),
      plot.title = element_text(face = "plain", size = 12, hjust = 0, 
                                margin = margin(t = 12, b = 6)),
      plot.title.position = "plot",
      plot.subtitle = element_text(face = "bold", size = 14, hjust = 0, 
                                margin = margin(b = 9)),
      strip.text.y = element_text(angle = 0, hjust = 0)
    )
}
```



```{r load stops data, include=FALSE}
stops <- here::here("analysis-data/stops.rds") %>% 
  read_rds()
```




```{r create report date strings}
# Lookup between boroughs and BCUs
borough_to_bcu <- tribble(
  ~borough, ~bcu,
  "London", "London",
  "Barking and Dagenham", "East",
  "Barnet", "North West",
  "Bexley", "South East",
  "Brent", "North West",
  "Bromley", "South",
  "Camden", "Central North",
  "Croydon", "South",
  "Ealing", "West",
  "Enfield", "North",
  "Greenwich", "South East",
  "Hackney", "Central East",
  "Hammersmith and Fulham", "Central West",
  "Haringey", "North",
  "Harrow", "North West",
  "Havering", "East",
  "Hillingdon", "West",
  "Hounslow", "West",
  "Islington", "Central North",
  "Kensington and Chelsea", "Central West",
  "Kingston upon Thames", "South West",
  "Lambeth", "Central South",
  "Lewisham", "South East",
  "Merton", "South West",
  "Newham", "North East",
  "Redbridge", "East",
  "Richmond upon Thames", "South West",
  "Southwark", "Central South",
  "Sutton", "South",
  "Tower Hamlets", "Central East",
  "Waltham Forest", "North East",
  "Wandsworth", "South West",
  "Westminster", "Central West"
)

report_bcu <- params$bcu
report_boroughs <- borough_to_bcu %>% 
  filter(bcu == report_bcu) %>% 
  pull("borough")

date_end <- stops %>% 
  pluck("date") %>% 
  max() %>% 
  as_date() %>% 
  ceiling_date(unit = "months") - days(1)
date_start <- date_end - years(1) + days(1)

report_period <- str_glue(
  format(date_start, ifelse(year(date_start) == year(date_end), "%B", "%B %Y")),
  " to ",
  format(date_end, "%B %Y")
)

report_between <- str_replace(report_period, " to ", " and ")
report_span <- str_replace(report_period, " to ", "â€“")
# `report_q` is used in file names -- it refers to quarters rather than years
# because the reports are produced quarterly
report_q <- str_glue(
  year(date_end),
  "_",
  case_when(
    month(date_end) %in% 1:3 ~ "q1",
    month(date_end) %in% 4:6 ~ "q2",
    month(date_end) %in% 7:9 ~ "q3",
    month(date_end) %in% 10:12 ~ "q4",
    TRUE ~ NA_character_
  )
)

# Create directory for files from this report
report_dir <- here::here(str_glue("output/{report_q}"))
if (!dir.exists(report_dir)) dir.create(report_dir)
```



```{r load other data, include=FALSE}
people <- here::here("analysis-data/people-by-borough.rds") %>% 
  read_rds() %>% 
  left_join(borough_to_bcu, by = "borough") %>% 
  select(-borough) %>%
  filter(!is.na(bcu)) %>% 
  group_by(across(where(is.character))) %>% 
  summarise(people = sum(people), .groups = "drop")

imd <- read_rds(here::here("analysis-data/imd.rds"))

london_stations <- here::here("analysis-data/stations.gpkg") %>% 
  st_read(quiet = TRUE) %>% 
  rownames_to_column(var = "id") %>% 
  mutate(id = as.numeric(id))

# Download data if needed
tribble(
  ~file, ~url,
  "lsoa", "https://opendata.arcgis.com/datasets/8bbadffa6ddc493a94078c195a1e293b_0.geojson",
  "borough", "https://opendata.arcgis.com/datasets/0e07a8196454415eab18c40a54dfbbef_0.geojson",
  "ward_lookup", "https://opendata.arcgis.com/datasets/e169bb50944747cd83dcfb4dd66555b1_0.csv",
  "ward", "https://opendata.arcgis.com/datasets/446d684e667a4d91bd54a073efff207d_0.geojson"
) %>% 
  pwalk(function (url, file) {
    file_type <- str_extract(url, "\\.\\w+$")
    file_name <- str_glue("{report_dir}/data_{file}{file_type}")
    if (!file.exists(file_name)) {
      download.file(url = url, destfile = file_name, timeout = 600)
    }
  })

# https://geoportal.statistics.gov.uk/datasets/lower-layer-super-output-areas-december-2011-boundaries-generalised-clipped-bgc-ew-v3
lsoa <- str_glue("{report_dir}/data_lsoa.geojson") %>% 
  read_sf() %>% 
  select(lsoa_code = LSOA11CD, lsoa_name = LSOA11NM, geometry) %>% 
  st_transform(27700)

# https://geoportal.statistics.gov.uk/datasets/local-authority-districts-december-2019-boundaries-uk-bgc
london_boroughs <- str_glue("{report_dir}/data_borough.geojson") %>% 
  read_sf() %>%
  clean_names() %>% 
  filter(str_detect(lad19cd, "^E09")) %>% 
  rename(borough = lad19nm) %>% 
  left_join(borough_to_bcu, by = "borough") %>% 
  st_transform(27700)

london_bcu <- london_boroughs %>% 
  group_by(bcu) %>% 
  summarise(bcu = first(bcu))

london_outline <- london_boroughs %>% 
  st_union() %>% 
  st_sf() %>% 
  mutate(region = "London")

ward_lad_lookup <- str_glue("{report_dir}/data_ward_lookup.csv") %>% 
  read_csv() %>% 
  clean_names() %>% 
  filter(str_detect(lad19cd, "^E09")) %>% 
  select(wd19cd, borough = lad19nm)

london_wards <- str_glue("{report_dir}/data_ward.geojson") %>% 
  read_sf() %>% 
  clean_names() %>% 
  st_transform(27700) %>% 
  left_join(ward_lad_lookup, by = "wd19cd") %>% 
  filter(!is.na(borough)) %>% 
  select(ward = wd19nm, borough, geometry)
```



```{r check data values are as expected, include=FALSE}
# check data only contains known variables
assert_that(setequal(
  names(stops), 
  c(
    "force",
    "type",
    "date",
    "latitude",
    "longitude",
    "gender",
    "age_range",
    "self_defined_ethnicity",
    "officer_defined_ethnicity",
    "legislation",
    "object_of_search",
    "outcome"
  )
))

# check factors only have known levels
assert_that(all(unique(stops$force) %in% c("British Transport Police", "City of London Police", "Metropolitan Police Service")))
assert_that(all(unique(stops$type) %in% c("Person search", "Person and Vehicle search", "Vehicle search")))
assert_that(all(unique(stops$gender) %in% c("male", "female", "other", NA_character_)))
assert_that(all(unique(stops$age_range) %in% c("under 10", "10-17", "18-24", "25-34", "over 34", NA_character_)))
assert_that(all(unique(stops$self_defined_ethnicity) %in% c(
  "Asian/Asian British - Any other Asian background", 
  "Asian/Asian British - Bangladeshi", 
  "Asian/Asian British - Chinese", 
  "Asian/Asian British - Indian", 
  "Asian/Asian British - Pakistani", 
  "Black/African/Caribbean/Black British - African", 
  "Black/African/Caribbean/Black British - Any other Black/African/Caribbean background",
  "Black/African/Caribbean/Black British - Caribbean", 
  "Mixed/Multiple ethnic groups - Any other Mixed/Multiple ethnic background", 
  "Mixed/Multiple ethnic groups - White and Asian", 
  "Mixed/Multiple ethnic groups - White and Black African", 
  "Mixed/Multiple ethnic groups - White and Black Caribbean", 
  "Other ethnic group - Any other ethnic group", 
  "Other ethnic group - Not stated", 
  "White - Any other White background", 
  "White - English/Welsh/Scottish/Northern Irish/British", 
  "White - Irish",
  NA_character_
)))
assert_that(all(unique(stops$officer_defined_ethnicity) %in% c("Asian", "Black", "Other", "White", NA_character_)))
assert_that(all(unique(stops$legislation) %in% c(
  "Criminal Justice and Public Order Act 1994 (section 60)", 
  "Deer Act 1991 (section 12)", 
  "Firearms Act 1968 (section 47)", 
  "Misuse of Drugs Act 1971 (section 23)", 
  "Police and Criminal Evidence Act 1984 (section 1)", 
  "Police and Criminal Evidence Act 1984 (section 6)", 
  "Psychoactive Substances Act 2016 (s36(2))", 
  "Wildlife and Countryside Act 1981 (section 19)", 
  NA_character_
)))
assert_that(all(unique(stops$object_of_search) %in% c(
  "anything to threaten or harm anyone", 
  "article for use in theft", 
  "articles for use in criminal damage",
  "controlled drugs", 
  "crossbows", 
  "evidence of offences under the act", 
  "evidence of wildlife offences",
  "firearms", 
  "fireworks",
  "goods on which duty has not been paid etc.", 
  "offensive weapons",
  "psychoactive substances", 
  "stolen goods",
  NA_character_
)))
assert_that(all(unique(stops$outcome) %in% c(
  "a no further action disposal", 
  "arrest",
  "caution (simple or conditional)",
  "community resolution",
  "khat or cannabis warning",
  "local resolution",
  "nothing found - no further action",
  "offender given drugs possession warning",
  "offender given penalty notice",
  "penalty notice for disorder",
  "summons / charged by post", 
  "suspect arrested",
  "suspect summonsed to court",
  NA_character_
)))

# check date/time is POSIXct
assert_that(all(is.POSIXct(stops$date)))

# check co-ordinates are valid
# bounding box co-ordinates from https://gist.github.com/graydon/11198540
assert_that(all(is.double(stops$longitude)))
assert_that(all(stops$longitude >= -180, na.rm = TRUE))
assert_that(all(stops$longitude <= 180, na.rm = TRUE))
assert_that(all(is.double(stops$latitude)))
assert_that(all(stops$latitude >= -90, na.rm = TRUE))
assert_that(all(stops$latitude <= 90, na.rm = TRUE))
```



```{r remove non-London BTP stops}
# BTP data includes all stops, wherever in England and Wales they occurred. We
# can remove those stops occurring outside the Greater London boundary, although
# this means that BTP stops without a location (some of which are likely to have
# occurred in London) will also be excluded.
btp_london_stops <- stops %>% 
  filter(force == "British Transport Police", !is.na(latitude), 
         !is.na(longitude)) %>% 
  st_as_sf(coords = c("longitude", "latitude"), crs = 4326, remove = FALSE) %>% 
  st_transform(27700) %>% 
  st_join(london_outline) %>% 
  filter(region == "London") %>% 
  st_drop_geometry() %>% 
  select(-region)

stops <- stops %>% 
  filter(force != "British Transport Police") %>% 
  bind_rows(btp_london_stops)
```



```{r add borough name, include=FALSE}
stops <- stops %>% 
  st_as_sf(
    coords = c("longitude", "latitude"), 
    crs = 4326, 
    remove = FALSE, 
    na.fail = FALSE
  ) %>% 
  st_transform(27700) %>% 
  st_join(
    select(london_boroughs, borough_code = lad19cd, borough_name = borough, bcu)
  ) %>% 
  st_drop_geometry()
```



```{r harmonise variables}
stops <- stops %>% 
  mutate(
    object_of_search = case_when(
      legislation == "Criminal Justice and Public Order Act 1994 (section 60)" ~ 
        "offensive weapons",
      TRUE ~ object_of_search
    ),
    object = recode(
      object_of_search,
      "controlled drugs" = "drugs",
      "offensive weapons" = "weapons",
      "evidence of offences under the act" = "unknown",
      "articles for use in criminal damage" = "other",
      "article for use in theft" = "other",
      "evidence of wildlife offences" = "other",
      "fireworks" = "other",
      "goods on which duty has not been paid etc." = "other",
      "anything to threaten or harm anyone" = "weapons",
      "crossbows" = "weapons",
      "psychoactive substances" = "drugs"
    ),
    outcome = recode(
      outcome,
      "suspect arrested" = "arrest",
      "community resolution" = "community/local resolution",
      "local resolution" = "community/local resolution",
      "caution (simple or conditional)" = "caution",
      "offender cautioned" = "caution",
      "khat or cannabis warning" = "drugs warning",
      "offender given penalty notice" = "fixed penalty",
      "penalty notice for disorder" = "fixed penalty",
      "offender given drugs possession warning" = "drugs warning",
      "a no further action disposal" = "no further action",
      "nothing found - no further action" = "no further action",
      "suspected psychoactive substances seized - no further action" = 
        "no further action",
      "summons / charged by post" = "charged by post",
      "suspect summonsed to court" = "charged by post"
    ),
    year = year(date),
    year_month = yearmonth(date)
  ) %>% 
  replace_na(list(object = "unknown", outcome = "unknown")) %>% 
  mutate(
    outcome = fct_relevel(
      outcome,
      "arrest",
      "charged by post",
      "caution",
      "fixed penalty",
      "community/local resolution",
      "drugs warning",
      "no further action",
      "unknown"
    )
  ) %>% 
  filter(year >= 2018)
```



```{r count stops and analyse trend, include=FALSE}
monthly_counts <- stops %>% 
  count(bcu, year_month) %>% 
  group_by(bcu) %>% 
  mutate(
    year_month = as_date(year_month),
    diff = n - lag(n),
    diff_perc = diff / lag(n)
  ) %>% 
  ungroup()

monthly_counts_feats <- monthly_counts %>% 
  as_tsibble(key = bcu, index = year_month) %>% 
  features(n, feat_stl)

monthly_counts_anomaly <- monthly_counts %>% 
  nest(data = -bcu) %>% 
  mutate(
    anomalies = map(
      data, 
      timetk::tk_anomaly_diagnostics, 
      .date_var = year_month, 
      .value = n, 
      .message = FALSE
    )
  ) %>% 
  select(-data) %>% 
  unnest(cols = anomalies)

total_searches_by_object <- stops %>% 
  filter(date >= date_start) %>% 
  count(bcu, object) %>% 
  group_by(bcu) %>% 
  mutate(prop = n / sum(n)) %>% 
  ungroup() %>% 
  arrange(bcu, desc(prop))
```



```{r search types}
main_types <- c("drugs", "firearms", "stolen goods", "weapons")

searches_by_type <- count(stops, bcu, year_month, object)
```



```{r search results by month}
search_result_annual_counts <- stops %>% 
  filter(date >= date_start, outcome != "unknown") %>% 
  mutate(positive = outcome != "no further action") %>% 
  count(bcu, positive) %>% 
  group_by(bcu) %>% 
  mutate(prop = n / sum(n)) %>% 
  ungroup()

search_result_month_counts <- stops %>% 
  mutate(
    positive = !outcome %in% c("no further action", "unknown"),
    year_month = as_date(year_month)
  ) %>% 
  count(bcu, year_month, positive) %>% 
  group_by(bcu, year_month) %>% 
  mutate(prop = n / sum(n)) %>% 
  ungroup()
```



```{r search disparity}
person_stops <- filter(
  stops, 
  type %in% c("Person search", "Person and Vehicle search")
)

age_counts <- person_stops %>% 
  filter(date >= date_start, !is.na(age_range)) %>% 
  tabyl(bcu, age_range) %>% 
  pivot_longer(-bcu, names_to = "age_range", values_to = "n") %>% 
  group_by(bcu) %>% 
  mutate(percent = n / sum(n)) %>% 
  ungroup()

sde_counts <- person_stops %>% 
  filter(date >= date_start, !is.na(self_defined_ethnicity)) %>% 
  mutate(
    sde_group = case_when(
      self_defined_ethnicity == "Other ethnic group - Not stated" ~ 
        NA_character_,
      str_detect(self_defined_ethnicity, "^Asian") ~ "Asian/Asian British",
      str_detect(self_defined_ethnicity, "^Black") ~ "Black/Black British",
      str_detect(self_defined_ethnicity, "^Mixed") ~ 
        "from multiple ethnic groups",
      str_detect(self_defined_ethnicity, "^Other") ~ 
        "from another ethnic group",
      str_detect(self_defined_ethnicity, "^White") ~ "white",
      TRUE ~ NA_character_
    )
  ) %>% 
  count(bcu, sde_group) %>% 
  group_by(bcu) %>% 
  mutate(
    percent = n / sum(n), 
    # Create a temporary column that contains search counts only for rows 
    # representing known SDE groups and NA otherwise, then use that column to
    # calculate the valid percentages
    known_n = ifelse(!is.na(sde_group), n, NA), 
    valid_percent = known_n / sum(known_n, na.rm = TRUE)
  ) %>%
  ungroup() %>% 
  select(-known_n) %>% 
  arrange(bcu, desc(percent))

stops_disparity <- person_stops %>% 
  filter(
    !is.na(bcu),
    date >= date_start, 
    !is.na(gender),
    gender %in% c("female", "male"),
    !is.na(age_range), 
    age_range != "under 10",
    !str_detect(self_defined_ethnicity, "^Other ethnic group")
  ) %>% 
  rename(sex = gender) %>% 
  count(bcu, sex, age_range, self_defined_ethnicity, name = "searches") %>% 
  {
    x <- .
    y <- x %>% 
      count(sex, age_range, self_defined_ethnicity, wt = searches, name = "searches") %>% 
      mutate(bcu = "London") %>% 
      bind_rows(x)
    y
  } %>%
  full_join(
    people, 
    by = c("bcu", "sex", "age_range", "self_defined_ethnicity")
  ) %>% 
  replace_na(list(searches = 0, people = 0)) %>% 
  separate(self_defined_ethnicity, c("ethnic_group", "ethnicity"), " - ") %>% 
  group_by(bcu, age_range, ethnic_group, sex) %>% 
  summarise(people = sum(people), searches = sum(searches), .groups = "drop") %>% 
  mutate(
    ethnic_group = str_extract(ethnic_group, "^\\w+"),
    age_label = case_when(
      age_range %in% c("under 10", "10-17") & sex == "female" ~ "girls",
      age_range %in% c("under 10", "10-17") & sex == "male" ~ "boys",
      !age_range %in% c("under 10", "10-17") & sex == "female" ~ "women",
      !age_range %in% c("under 10", "10-17") & sex == "male" ~ "men",
    ),
    group = str_glue("**{age_label}** aged **{age_range}** identifying as ",
                     "**{ethnic_group}**"),
    search_rate = searches / (people / 1000)
  )

stops_disparity_object <- person_stops %>% 
  mutate(
    object = case_when(
      object == "weapons" & 
        legislation == "Police and Criminal Evidence Act 1984 (section 1)" ~ 
        "weapons (based on reasonable suspicion)",
      object == "weapons" & 
        legislation == "Criminal Justice and Public Order Act 1994 (section 60)" ~ 
        "weapons (based on authorisation)",
      object == "weapons" ~ "unknown",
      TRUE ~ object
    )
  ) %>% 
  filter(
    date >= date_start, 
    !is.na(age_range), 
    age_range != "under 10",
    !is.na(gender),
    gender %in% c("female", "male"),
    !object %in% c("other", "unknown"),
    !str_detect(self_defined_ethnicity, "^Other ethnic group")
  ) %>% 
  select(bcu, object, sex = gender, age_range, self_defined_ethnicity) %>% 
  mutate_if(is.character, as.factor) %>% 
  count(
    bcu, object, sex, age_range, self_defined_ethnicity, 
    name = "searches", 
    .drop = FALSE
  ) %>% 
  left_join(
    people, 
    by = c("bcu", "sex", "age_range", "self_defined_ethnicity")
  ) %>% 
  separate(self_defined_ethnicity, c("ethnic_group", "ethnicity"), " - ") %>% 
  group_by(bcu, object, age_range, ethnic_group, sex) %>% 
  summarise(people = sum(people), searches = sum(searches), 
            .groups = "drop") %>% 
  mutate(
    ethnic_group = str_extract(ethnic_group, "^\\w+"),
    age_label = case_when(
      age_range %in% c("under 10", "10-17") & sex == "female" ~ "girls",
      age_range %in% c("under 10", "10-17") & sex == "male" ~ "boys",
      !age_range %in% c("under 10", "10-17") & sex == "female" ~ "women",
      !age_range %in% c("under 10", "10-17") & sex == "male" ~ "men",
    ),
    group = str_glue("{age_label}, {age_range}, {ethnic_group}"),
    search_rate = searches / (people / 1000)
  )

stops_model <- stops_disparity %>% 
  filter(!is.na(bcu), search_rate > 0) %>% 
  # Set reference categories for each categorical variable
  mutate(
    age_range = fct_relevel(age_range, "over 34"),
    ethnic_group = fct_relevel(ethnic_group, "White"),
    sex = fct_relevel(sex, "female")
  ) %>% 
  nest(data = -bcu) %>% 
  mutate(model = map(
    data, 
    ~ broom::tidy(glm(log(search_rate) ~ sex + age_range + ethnic_group, data = .))
  )) %>% 
  select(-data) %>% 
  unnest(model) %>% 
  # Extract the ethnicity term with the largest co-efficient for each BCU, then
  # join that co-efficient to all the rows for that BCU so it can be used to
  # filter later on
  {
    data <- .
    largest_ethnicity_term <- data %>% 
      filter(str_detect(term, "^ethnic_group")) %>% 
      group_by(bcu) %>% 
      slice_max(estimate, n = 1) %>% 
      select(bcu, largest_ethnicity_term = estimate)
    left_join(data, largest_ethnicity_term, by = "bcu")
  } %>% 
  group_by(bcu) %>%
  arrange(desc(estimate)) %>%
  ungroup() %>% 
  # keep only model terms that are greater than zero, significant and greater 
  # than the largest co-efficients for ethnicity
  filter(estimate > 0, estimate > largest_ethnicity_term, p.value < 0.05) %>% 
  select(-largest_ethnicity_term) %>% 
  mutate(
    term = case_when(
      str_detect(term, "^age_range") ~
        str_glue("being aged {str_remove(term, '^age_range')}"),
      str_detect(term, "^sex") ~ str_glue("being {str_remove(term, '^sex')}"),
      TRUE ~ term
    )
  ) %>% 
  select(bcu, term) %>% 
  nest(data = term) %>% 
  # Collapse age categories if consecutive categories are present
  mutate(data = map(data, function (x) {
    x <- pull(x, "term")
    if ("being aged 10-17" %in% x & "being aged 18-24" %in% x & 
        "being aged 25-34" %in% x) {
        c(str_subset(x, "^being aged", negate = TRUE), "being aged under 35")
    } else if ("being aged 10-17" %in% . & "being aged 18-24" %in% .) {
        c(str_subset(x, "^being aged", negate = TRUE), "being aged under 25")
    } else if ("being aged 18-24" %in% . & "being aged 25-34" %in% .) {
        c(str_subset(x, "^being aged", negate = TRUE), "being aged 18-34")
    } else {
        x
    }
  }))

overall_search_rate <- stops_disparity %>% 
  filter(!is.na(bcu)) %>% 
  group_by(bcu) %>% 
  summarise(searches = sum(searches), people = sum(people)) %>% 
  mutate(rate = searches / (people / 1000))
```



```{r searches by borough and ward, include=FALSE}
# Create a version of the data that is an SF object
stops_sf <- stops %>% 
  filter(!is.na(latitude), !is.na(longitude), date >= date_start) %>% 
  st_as_sf(coords = c("longitude", "latitude"), crs = 4326) %>% 
  st_transform(27700)

# Count number of searches for each borough
searches_by_borough <- stops_sf %>% 
  st_join(london_boroughs) %>% 
  as_tibble() %>% 
  count(borough, name = "searches") %>% 
  filter(!is.na(borough)) %>% 
  mutate(searches_per_month = searches / 12) %>% 
  arrange(desc(searches))

# Count number of searches by BCU
searches_by_bcu <- searches_by_borough %>% 
  left_join(borough_to_bcu, by = "borough") %>% 
  count(bcu, wt = searches, sort = TRUE) %>% 
  filter(!is.na(bcu)) %>% 
  left_join(count(people, bcu, wt = people), by = "bcu") %>% 
  rename(searches = n.x, people = n.y) %>% 
  mutate(
    rank_text = case_when(
      row_number() == 1 ~ "highest number of", 
      row_number() == 2 ~ "second highest number of", 
      row_number() == 3 ~ "third highest number of", 
      row_number() == n() - 2 ~ "third lowest number of", 
      row_number() == n() - 1 ~ "second lowest number of", 
      row_number() == n() ~ "lowest number of", 
      TRUE ~ as.character(str_glue("{ordinal(row_number())} most"))
    ),
    rate = searches / (people / 1000),
    rate_rank = min_rank(desc(rate)), 
    rate_rank_text = case_when(
      rate_rank == 1 ~ "highest", 
      rate_rank == 2 ~ "second highest", 
      rate_rank == 3 ~ "third highest", 
      rate_rank == n() - 2 ~ "third lowest", 
      rate_rank == n() - 1 ~ "second lowest", 
      rate_rank == n() ~ "lowest", 
      TRUE ~ as.character(str_glue("{ordinal(rate_rank)} highest"))
    )
  )

# Count number of searches for each ward
searches_by_ward <- stops_sf %>% 
  st_join(london_wards) %>% 
  as_tibble() %>% 
  count(borough, ward, name = "searches") %>% 
  filter(!is.na(borough), !is.na(ward)) %>% 
  mutate(label = as.character(str_glue("{ward} ({borough})"))) %>% 
  arrange(desc(searches)) %>% 
  left_join(borough_to_bcu, by = "borough")

# Count number of searches for each LSOA
stops_by_lsoa <- stops_sf %>% 
  st_join(lsoa) %>% 
  st_set_geometry(NULL) %>% 
  mutate(object = case_when(
    object == "weapons" & 
      legislation == "Criminal Justice and Public Order Act 1994 (section 60)" ~ 
      "weapons under section 60",
    object == "weapons" ~ "weapons under section 1",
    TRUE ~ object
  ))

# this code first identifies all the LSOAs in London, then counts the searches 
# in each one, since this keeps the LSOAs with zero searches
stop_concentration <- lsoa %>% 
  st_join(london_boroughs) %>% 
  filter(!is.na(borough)) %>% 
  st_set_geometry(NULL) %>% 
  select(lsoa_code) %>% 
  left_join(
    count(stops_by_lsoa, bcu, lsoa_code, name = "searches"), 
    by = "lsoa_code"
  ) %>% 
  filter(!is.na(bcu)) %>% 
  replace_na(list(searches = 0)) %>% 
  arrange(desc(searches)) %>% 
  mutate(
    csum_searches = cumsum(searches),
    csum_searches = csum_searches / max(csum_searches),
    perc_rank = row_number() / n()
  ) %>% 
  filter(csum_searches > 0.5) %>% 
  group_by(bcu) %>% 
  slice(1) %>% 
  select(bcu, perc_rank)

# Identify the boroughs (if any) with fewer searches than the ward in the report 
# BCU with the highest number of searches
low_search_boroughs <- searches_by_borough %>% 
  filter(searches < pluck(filter(searches_by_ward, bcu == report_bcu), "searches", 1)) %>% 
  pull(borough)
```



```{r headlines}
headline1 <- str_glue(
  "Police in {report_bcu} BCU ({knitr::combine_words(report_boroughs)} ",
  "boroughs) stopped and searched ",
  comma(pluck(filter(searches_by_bcu, bcu == report_bcu), "searches", 1)),
  " people and vehicles in the 12~months from {report_period}. The number ",
  "of searches has generally ",
  ifelse(
    pluck(filter(monthly_counts_feats, bcu == report_bcu), "linearity") > 0, 
    "increased", 
    "decreased"
  ),
  " over the past two years."
)

headline2 <- str_replace_all(str_glue(
  percent(
    pluck(filter(total_searches_by_object, bcu == report_bcu), "prop", 1)
  ),
  " of searches in that period were for ",
  pluck(filter(total_searches_by_object, bcu == report_bcu), "object", 1),
  ", with ",
  percent(pluck(
    filter(search_result_annual_counts, bcu == report_bcu, !positive), 
    "prop"
  )),
  " of all searches resulting in no further action."
), "%", "\\\\%")

# headline3 <- str_glue(
#   "Different demographic groups are searched at different rates, with ",
#   str_remove_all(pluck(arrange(stops_disparity, desc(search_rate)), "group", 1), 
#                  "\\*\\*"),
#   " being ", 
#   number(
#     pluck(arrange(stops_disparity, desc(search_rate)), "search_rate", 1) / 
#       overall_search_rate
#   ), 
#   " times more likely to be searched than the population as a whole."
# )

headline4 <- str_replace_all(str_glue(
  "Searches are heavily concentrated in some areas -- half of all searches ",
  "occurred in ", 
  percent(pluck(filter(stop_concentration, bcu == report_bcu), "perc_rank", 1)), 
  " of neighbourhoods."
), "%", "\\\\%")
```



<!-- single space at the end of each sentence -->
\frenchspacing

<!-- left align as per UCL style guide -->
\raggedright

<!-- prevent vertical justification of paragraphs -->
\raggedbottom

<!-- The following blocks of Latex code produce the title page -->

\begin{textblock*}{21cm}(0mm, 0mm)
\includegraphics[width=21cm,height=29.7cm]{`r str_glue("cover_image_{report_q}.jpg")`}
\end{textblock*}

\begin{textblock*}{21cm}(0mm, 0mm)
\includegraphics[width=21cm]{ucl-banner-port-yellow-rgb-lg.png}
\end{textblock*}

\begin{textblock*}{21cm}(1cm,1cm)
\textbf{\sffamily INSTITUTE FOR GLOBAL CITY POLICING}
\end{textblock*}

\begin{textblock*}{18cm}(3cm, 13.66cm)
\raggedright \sffamily
\begin{singlespace}
\colorbox{white}{\hspace{1cm}\parbox[c][5.9cm]{16cm}{
{\fontsize{40}{32}\selectfont \bfseries 
\mbox{Stop and search}\\\mbox{in `r report_bcu` BCU}
\vspace{6pt}}

{\fontsize{36}{30}\selectfont \mbox{`r report_period`} }

}\hspace{1cm}}
\end{singlespace}
\end{textblock*}

\begin{textblock*}{11.43cm}(0cm, 24.13cm)
\colorbox{uclyellow}{\parbox[c][2.63cm]{\textwidth}{
\centering \bfseries \sffamily \fontsize{16}{16}\selectfont 
Dr Matt Ashby\ \ |\ \ `r format(Sys.time(), "%B %Y")`
}}
\end{textblock*}

\ 

\thispagestyle{empty}
\newpage



# Main points



\textbf{\sffamily `r headline1`}

\textbf{\sffamily `r headline2`}

\textbf{\sffamily `r headline4`}



```{r Twitter cover image, include=FALSE}
cover_bg <- str_glue("output/cover_image_{report_q}.jpg") %>% 
  here::here() %>% 
  image_read() %>% 
  image_scale("1200x") %>% 
  image_crop("x800", gravity = "West")
cover_logo <- here::here("output/ucl-banner-land-yellow-rgb.png") %>% 
  image_read() %>% 
  image_scale("1200x")

twitter_cover <- image_composite(cover_bg, cover_logo) %>% 
  image_annotate("INSTITUTE FOR GLOBAL CITY POLICING", location = "+17+17",
                 font = "Arial", size = 13.5, weight = 700) %>%
  image_draw()
rect(200, 280, 1200, 560, col = "white", border = NA)
text(235, 370, "Stop and search", adj = c(0, 0), family = "Arial", cex = 6, font = 2)
text(235, 405, "in London", adj = c(0, 0.5), family = "Arial", cex = 6, font = 2)
text(235, 440, report_period, adj = c(0, 1), family = "Arial", cex = 6)
dev.off()

image_write(twitter_cover, str_glue("{report_q}_00_cover.png"))
```



# Introduction

Stop and search is a legal power that allows police officers to search people to find out if they are carrying prohibited items such as drugs, weapons or stolen goods. Stop and search means officers can confirm if a person is or is not in possession of contraband without arresting them and taking them to a police station, but it is also a source of tension between police and communities. [A review by the College of Policing](https://whatworks.college.police.uk/Research/Documents/SS_and_crime_report.pdf) found little relationship between how many searches police do and how much crime occurs, but [police insist stop and search helps them fight crime](https://www.met.police.uk/advice/advice-and-information/st-s/stop-and-search/why-we-use-stop-and-search/). This report summarises how police used stop and search powers in the `r report_bcu` Basic Command Unit (the London boroughs of `r knitr::combine_words(report_boroughs)`) from `r report_period`.



(ref:chart-trend-overall) Number of stop-and-searches in `r report_bcu` BCU, `r format(min(stops$date), '%B %Y')` to `r {format(max(stops$date), '%B %Y')}`

```{r chart-trend-overall, fig.cap="(ref:chart-trend-overall)", fig.pos="h", message=FALSE, warning=FALSE}
weekly_counts <- stops %>% 
  filter(!is.na(bcu), date >= ymd("2018-04-01")) %>% 
  mutate(year_week = as_date(yearweek(date, week_start = 7))) %>% 
  count(bcu, year_week) %>% 
  group_by(year_week) %>% 
  mutate(
    median = median(n),
    higher = n > median,
    notting_hill = (
      bcu == "Central West" &
      year_week %in% as_date(yearweek(as_date(timeDate::holidayLONDON(year = 2018:year(today()))), week_start = 7)) &
      month(year_week) == 8 & 
      year(year_week) != 2020
    ),
    label = ifelse(
      notting_hill, 
      str_glue(
        "Notting Hill Carnival week\n{year(year_week)}: {comma(n, accuracy = 1)} ",
        "searches in\n{bcu} BCU"
      ), 
      NA_character_
    )
  ) %>% 
  ungroup()

weekly_counts_anomaly <- weekly_counts %>% 
  select(bcu, year_week, n) %>% 
  nest(data = -bcu) %>% 
  mutate(
    anomalies = map(
      data, 
      timetk::tk_anomaly_diagnostics, 
      .date_var = year_week, 
      .value = n, 
      .message = FALSE
    )
  ) %>% 
  select(-data) %>% 
  unnest(cols = anomalies) %>% 
  select(bcu, year_week, n = observed, anomaly) %>% 
  mutate(label = ifelse(
    bcu == report_bcu & anomaly == "Yes", 
    ifelse(
      month(year_week) == month(year_week + days(6)),
      str_glue(
        "{day(year_week)} to {day(year_week + days(6))} ",
        "{month(year_week + days(6), label = TRUE)}"
      ),
      str_glue(
        "{day(year_week)} {month(year_week, label = TRUE)} to ",
        "{day(year_week + days(6))} {month(year_week + days(6), label = TRUE)}"
      )
    ), 
    NA_character_
  ))

chart_trend <- ggplot() +
  # Lines for other BCUs
  geom_line(
    aes(year_week, n, group = bcu, colour = "other"), 
    data = filter(weekly_counts, bcu != report_bcu), 
    alpha = 0.5
  ) +
  # Labels for anomalous weeks
  geom_label_repel(
    aes(year_week, n, label = label),
    data = weekly_counts_anomaly,
    na.rm = TRUE,
    direction = "x",
    hjust = 0,
    label.padding = 0,
    label.size = NA,
    min.segment.length = 0,
    segment.colour = ucl_colours_list[["Orange"]],
    size = 3
  ) +
  # White background for anomaly points
  geom_point(
    aes(year_week, n),
    data = filter(weekly_counts_anomaly, anomaly == "Yes", bcu == report_bcu),
    colour = ucl_colours_list[["Orange"]],
    fill = "white",
    shape = 21,
    size = 3
  ) +
  # Inner points for anomalies
  geom_point(
    aes(year_week, n),
    data = filter(weekly_counts_anomaly, anomaly == "Yes", bcu == report_bcu),
    colour = ucl_colours_list[["Orange"]],
    shape = 16,
    size = 1.5
  ) +
  # Line for report BCU
  geom_line(
    aes(year_week, n, group = bcu, colour = "bcu"), 
    data = filter(weekly_counts, bcu == report_bcu)
  ) +
  # Outer points for anomalies
  geom_point(
    aes(year_week, n),
    data = filter(weekly_counts_anomaly, anomaly == "Yes", bcu == report_bcu),
    colour = ucl_colours_list[["Orange"]],
    shape = 21,
    size = 3
  ) +
  # Labels for NHC weeks
  geom_label(
    aes(year_week + days(7), 1250, label = label),
    data = weekly_counts,
    na.rm = TRUE,
    hjust = 0,
    label.size = NA,
    lineheight = 1,
    size = 3,
    vjust = 1
  ) +
  # Labels for this year
  annotate(
    "segment", 
    x = date_start, 
    xend = date_end, 
    y = 0, 
    yend = 0, 
    colour = chart_elements$label_line_colour
  ) +
  annotate(
    "point", 
    x = date_start, 
    y = 0, 
    colour = chart_elements$label_line_colour,
    shape = "|"
  ) +
  annotate(
    "point", 
    x = date_end, 
    y = 0, 
    colour = chart_elements$label_line_colour,
    shape = "|"
  ) +
  annotate(
    "label", 
    x = mid_point(date_start, date_end), 
    y = 0, 
    colour = chart_elements$label_text_colour,
    hjust = 0.5, 
    label = "12 months used for this report", 
    label.size = NA,
    size = chart_elements$label_text_size * 0.9, 
    vjust = 0.5
  ) +
  # Labels for previous year
  annotate(
    "segment", 
    x = date_start - years(1), 
    xend = date_start, 
    y = 0, 
    yend = 0, 
    colour = chart_elements$label_line_colour
  ) +
  annotate(
    "point", 
    x = date_start - years(1), 
    y = 0, 
    colour = chart_elements$label_line_colour,
    shape = "|"
  ) +
  annotate(
    "point", 
    x = date_start, 
    y = 0, 
    colour = chart_elements$label_line_colour,
    shape = "|"
  ) +
  annotate(
    "label", 
    x = mid_point(date_start - years(1), date_start), 
    y = 0, 
    colour = chart_elements$label_text_colour,
    hjust = 0.5, 
    label = "previous 12 months", 
    label.size = NA,
    size = chart_elements$label_text_size * 0.9, 
    vjust = 0.5
  ) +
  # Specify limits here so that lines are cut off rather than data outside 
  # limits being replaced with NAs, see:
  # https://stackoverflow.com/a/25685952/8222654
  coord_cartesian(ylim = c(0, 1300), clip = "off") +
  scale_x_date(
    date_breaks = "3 months", 
    date_labels = "%b\n%Y", 
    expand = c(0.025, 0)
  ) +
  scale_y_continuous(
    labels = comma_format(), 
    # limits = c(0, 1200), 
    expand = expansion(mult = 0),
    position = "right"
  ) + 
  scale_colour_manual(
    values = c("bcu" = ucl_colours_list[["Orange"]], other = "grey80"),
    labels = c("bcu" = str_glue("{report_bcu} BCU"), other = "other BCUs")
  ) +
  labs(
    x = NULL, 
    y = "number of searches per week", 
    colour = NULL
  ) +
  theme_stop_search() +
  theme(
    axis.ticks.x = element_blank(),
    axis.title.y = element_text(hjust = 0),
    legend.position = "bottom"
  )

# save_chart(
#   chart_trend, 
#   "01_trend",
#   "Number of stop-and-searches in London over time"
# )

chart_trend
```



**Between `r report_between`, police officers in `r report_bcu` BCU carried out `r comma(pluck(filter(searches_by_bcu, bcu == report_bcu), "searches", 1))` stop-and-searches**, or about `r comma(pluck(filter(searches_by_bcu, bcu == report_bcu), "searches", 1) / 52)` per week -- the `r pluck(filter(searches_by_bcu, bcu == report_bcu), "rate_rank_text")` rate of searches per 1,000 residents of any the `r nrow(searches_by_bcu)` Metropolitan Police BCUs. Of those, `r ifelse(prop_of_total(stops, force, force == "Metropolitan Police Service", bcu == report_bcu) > 0.999, "more than 99.9%", percent(prop_of_total(stops, force, force == "Metropolitan Police Service", bcu == report_bcu)))` were conducted by the Metropolitan Police and `r ifelse(prop_of_total(stops, force, force == "British Transport Police", bcu == report_bcu) < 0.001, "less than 0.1%", percent(prop_of_total(stops, force, force == "British Transport Police", bcu == report_bcu)))` by British Transport Police. Across both forces, `r percent(prop_of_total(stops, type, type == "Person search", bcu == report_bcu))` of stops were of pedestrians, `r percent(prop_of_total(stops, type, type == "Person and Vehicle search", bcu == report_bcu))` of people in vehicles and `r percent(prop_of_total(stops, type, type == "Vehicle search", bcu == report_bcu))` of only vehicles.



```{r}
# Calculate rolling annual change for the current BCU
rolling_counts_bcu <- monthly_counts %>% 
  filter(bcu == report_bcu) %>% 
  mutate(
    annual = slider::slide_int(n, sum, .before = 11, .complete = TRUE),
    annual_diff = annual - lag(annual, n = 12)
  )

# Calculate rolling annual average for London
rolling_counts_ldn <- monthly_counts %>% 
    count(year_month, wt = n) %>% 
    mutate(
        annual = slider::slide_int(n, sum, .before = 11, .complete = TRUE),
        annual_diff = annual - lag(annual, n = 12)
    )

# Describe BCU trend over the past year
annual_change_bcu <- str_glue(
  ifelse(
    nth(rolling_counts_bcu$annual, -1) - nth(rolling_counts_bcu$annual, -13) > 0,
    "increase",
    "decrease"
  ),
  " of ",
  percent(abs((nth(rolling_counts_bcu$annual, -1) - nth(rolling_counts_bcu$annual, -13)) / nth(rolling_counts_bcu$annual, -13)))
)

# Describe London trend over the past year
annual_change_ldn <- str_glue(
  ifelse(
    nth(rolling_counts_ldn$annual, -1) - nth(rolling_counts_ldn$annual, -13) > 0,
    "an increase",
    "a decrease"
  ),
  " of ",
  percent(abs((nth(rolling_counts_ldn$annual, -1) - nth(rolling_counts_ldn$annual, -13)) / nth(rolling_counts_ldn$annual, -13)))
)

```



The number of searches carried out in `r report_period` was **a year-on-year `r annual_change_bcu`** (Figure \@ref(fig:chart-trend-overall)) compared to `r annual_change_ldn` across London as a whole.



# What items are people searched for?

(ref:chart-search-types) Searches by type of object being searched for, `r report_period`

```{r chart-search-types, fig.asp=0.5, fig.cap="(ref:chart-search-types)", fig.pos="h"}
search_type_by_bcu <- searches_by_type %>% 
  filter(as_date(year_month) >= date_start, !is.na(bcu)) %>% 
  count(bcu, object, wt = n) %>% 
  group_by(bcu) %>% 
  mutate(
    prop = n / sum(n),
    # align = ifelse(prop > max(prop) / 2, 1, 0),
    # percent = percent(prop, accuracy = 0.1),
    this_bcu = ifelse(bcu == report_bcu, "bcu", "other")
  ) %>% 
  group_by(this_bcu, object) %>% 
  summarise(prop_min = min(prop), prop_max = max(prop), .groups = "drop") %>% 
  mutate(
    object = fct_relevel(fct_reorder(object, prop_max), "unknown", "other"),
    prop_range = prop_max - prop_min,
    prop_mid = prop_min + (prop_range / 2)
  )

chart_search_types <- ggplot() +
  # Rectangle to show range of values in other BCUs
  geom_tile(
    aes(x = prop_mid, width = prop_range, y = object, height = 0.5),
    data = filter(search_type_by_bcu, this_bcu != "bcu"),
    fill = "grey95"
  ) +
  # Line to show minimum value in other BCUs
  geom_spoke(
    aes(x = prop_min, y = object, angle = pi / 2, radius = 0.5),
    data = filter(search_type_by_bcu, this_bcu != "bcu"),
    colour = "grey75",
    position = position_nudge(y = -0.25)
  ) +
  # Line to show maximum value in other BCUs
  geom_spoke(
    aes(x = prop_max, y = object, angle = pi / 2, radius = 0.5),
    data = filter(search_type_by_bcu, this_bcu != "bcu"),
    colour = "grey75",
    position = position_nudge(y = -0.25)
  ) +
  # Line to show value for this BCU
  geom_segment(
    aes(x = 0, y = object, xend = prop_min, yend = object),
    data = filter(search_type_by_bcu, this_bcu == "bcu"),
    colour = ucl_colours_list[["Orange"]]
  ) +
  # Background point to show value for this BCU
  geom_point(
    aes(prop_mid, object, colour = this_bcu, group = this_bcu),
    data = filter(search_type_by_bcu, this_bcu == "bcu"),
    colour = ucl_colours_list[["Orange"]],
    fill = "white",
    shape = 21,
    size = 3
  ) +
  # Foreground point to show value for this BCU
  geom_point(
    aes(prop_mid, object, colour = this_bcu, group = this_bcu),
    data = filter(search_type_by_bcu, this_bcu == "bcu")
  ) +
  geom_text(
    aes(x = prop_mid, y = object, label = percent(prop_min, accuracy = 0.1)),
    data = filter(search_type_by_bcu, this_bcu == "bcu"),
    colour = chart_elements$label_text_colour,
    nudge_y = -0.25,
    size = chart_elements$label_text_size,
    vjust = 1
  ) +
  geom_text(
    aes(x = x, y = y, label = label),
    data = tibble(
      x = pluck(filter(search_type_by_bcu, object == first(object), this_bcu == "other"), "prop_mid", 1),
      y = first(search_type_by_bcu$object),
      label = "range of proportions in other BCUs"
    ),
    colour = chart_elements$label_text_colour,
    hjust = 1,
    position = position_nudge(x = -0.02, y = 0.5),
    size = chart_elements$label_text_size
  ) +
  scale_x_continuous(
    labels = percent_format(),
    expand = expansion(mult = c(0.025, 0.025))
  ) +
  scale_y_discrete(
    expand = expansion(
      mult = c(0.05, 2 / length(unique(search_type_by_bcu$object)))
    )
  ) +
  labs(
    x = "proportion of searches", 
    y = NULL,
    fill = NULL
  ) +
  theme_stop_search() +
  theme(
    legend.position = "none",
    panel.grid.major.x = element_line(),
    panel.grid.minor.x = element_line(),
    panel.grid.major.y = element_blank()
  )

# save_chart(
#   chart_search_types, 
#   "02_types",
#   str_glue("Searches by type of object being searched for, {report_period}"),
# )

chart_search_types
```



```{r search types change}
search_type_trends <- stops %>% 
  filter(bcu == report_bcu) %>% 
  count(year_month, object) %>% 
  filter(
    !object %in% c("other", "unknown"), 
    as_date(year_month) >= date_start
  ) %>% 
  arrange(object, year_month) %>% 
  mutate(change = n / first(n)) %>% 
  as_tsibble(key = object, index = year_month) %>% 
  model(lm = TSLM(change ~ trend())) %>% 
  mutate(coefs = map(lm, broom::tidy)) %>% 
  unnest(cols = coefs) %>% 
  filter(term == "trend()") %>% 
  mutate(abs_term = abs(estimate)) %>% 
  arrange(desc(abs_term))

search_type_increase <- search_type_trends %>% 
  filter(estimate > 0 & p.value < 0.05) %>% 
  pull("object")

search_type_decrease <- search_type_trends %>% 
  filter(estimate < 0 & p.value < 0.05) %>% 
  pull("object")

search_type_changes <- case_when(
  length(search_type_increase) == length(main_types) ~
    paste(to_text(search_type_increase), "have all increased"),
  length(search_type_decrease) == length(main_types) ~
    paste(to_text(search_type_decrease), "have all decreased"),
  length(search_type_increase) > 0 & length(search_type_decrease) > 0 ~
    paste(
      to_text(search_type_increase), "have increased while searches for",
      to_text(search_type_decrease), "have decreased"
    ),
  length(search_type_increase) > 0 ~
    paste(to_text(search_type_increase), "have significantly increased"),
  length(search_type_decrease) > 0 ~ 
    paste(to_text(search_type_decrease), "have significantly decreased"), 
  TRUE ~ NA_character_
)

search_type_changes <- ifelse(
  !is.na(search_type_changes),
  paste(
    "In the past 12 months, the number of searches for",
    search_type_changes,
    "(Figure \\@ref(fig:chart-search-types-change))."
  ),
  ""
)

most_common_search_types <- searches_by_type %>% 
  filter(as_date(year_month) >= date_start, bcu == report_bcu) %>% 
  count(object, wt = n) %>% 
  janitor::adorn_percentages(denominator = "col")

search_type_ranks <- searches_by_type %>% 
  filter(
    as_date(year_month) >= date_start, 
    !is.na(bcu), 
    !object %in% c("other", "unknown")
  ) %>% 
  count(bcu, object, wt = n) %>% 
  group_by(bcu) %>% 
  mutate(prop = n / sum(n)) %>% 
  group_by(object) %>% 
  mutate(
    rank_highest = min_rank(desc(prop)),
    rank_lowest = min_rank(prop)
  ) %>% 
  filter(bcu == report_bcu, rank_highest %in% 1:2 | rank_lowest %in% 1:2) %>% 
  mutate(across(
    c(rank_highest, rank_lowest), 
    recode, 
    `1` = "", 
    `2` = "second ", 
    .default = NA_character_
  )) %>%
  select(object, rank_highest, rank_lowest) %>% 
  pivot_longer(
    -object, 
    names_to = "category", 
    values_to = "rank", 
    names_prefix = "rank_", 
    values_drop_na = TRUE
  ) %>%
  arrange(category, rank, object) %>% 
  mutate(
    summary = as.character(str_glue("the {rank}{category} proportion of searches for {object}"))
  )
```



Police officers are empowered to search people for different items -- including drugs, items to use in theft or criminal damage, stolen goods, weapons and even some fireworks -- under different acts of parliament. Although police emphasise that stop and search "[protects Londoners by taking weapons off the streets](https://www.met.police.uk/police-forces/metropolitan-police/areas/about-us/about-the-met/stop-and-search/)", only about one in `r number_to_text(round(1 / pluck(filter(most_common_search_types, object == "weapons"), "n")))` searches in `r report_bcu` BCU between `r report_between` were for weapons -- **`r percent(pluck(slice_max(most_common_search_types, n), "n"))` of searches were for `r pluck(slice_max(most_common_search_types, n), "object")`** (Figure \@ref(fig:chart-search-types)). `r ifelse(nrow(search_type_ranks) > 0, str_glue("{report_bcu} BCU had ", knitr::combine_words(search_type_ranks$summary), " of the {length(na.omit(london_bcu$bcu))} Metropolitan Police BCUs."), "")`



(ref:chart-search-types-change) Change in number of searches by type, `r format(min(stops$date), '%B %Y')` to `r format(max(stops$date), '%B %Y')`

```{r chart-search-types-change, fig.cap="(ref:chart-search-types-change)", fig.pos="h"}
search_type_order <- searches_by_type %>% 
  filter(bcu == report_bcu, object %in% main_types) %>% 
  group_by(object) %>% 
  summarise(n = mean(n), .groups = "drop") %>% 
  arrange(desc(n)) %>% 
  pull(object)

chart_types_change <- stops %>%
  filter(
    bcu == report_bcu, 
    object %in% main_types, 
    year_month >= yearmonth(ymd("2018-06-01"))
  ) %>%
  count(bcu, year_month, object) %>% 
  group_by(object) %>% 
  arrange(year_month) %>% 
  mutate(
    change = n / first(n),
    year_month = as_date(year_month)
  ) %>% 
  ungroup() %>% 
  mutate(object = fct_relevel(object, search_type_order)) %>% 
  ggplot(aes(year_month, n, colour = object, group = bcu)) +
  geom_segment(aes(xend = year_month, yend = 0), colour = "grey70", 
               size = 0.25) +
  # geom_hline(aes(yintercept = 1), 
  #            colour = chart_elements$reference_line_colour) +
  geom_point(colour = "grey70", size = 0.75) +
  geom_smooth(method = "loess", formula = "y ~ x", se = FALSE) +
  scale_x_date(date_breaks = "1 year", date_labels = "'%y",
               expand = expansion(mult = c(0.025, 0.025))) +
  scale_y_continuous(
    labels = comma_format(accuracy = 1), 
    limits = c(0, NA),
    position = "right"
  ) +
  scale_colour_manual(values = search_type_colours) +
  facet_wrap(
    facets = vars(object), 
    nrow = 1,
    scales = "free", 
    labeller = as_labeller(function (string) paste("searches for\n", string))
  ) +
  labs(
    x = NULL, 
    y = "number of searches per month"
  ) +
  theme_stop_search() +
  theme(
    axis.title.y = element_text(hjust = 0),
    legend.position = "none"
  )

# save_chart(
#   chart_types_change, 
#   "03_types_change",
#   str_glue(
#     "Change in number of searches by type, ",
#     "{format(min(stops$date), '%B %Y')} to {format(max(stops$date), '%B %Y')}"
#   )
# )

chart_types_change
```



About `r percent(sum(pull(filter(most_common_search_types, object %in% main_types), "n")))` of searches are looking for the four main types of contraband: `r vector_to_text(main_types)`. `r search_type_changes`



```{r weapons trend, include=FALSE}
weapon_searches_by_month <- stops %>% 
  filter(
    legislation %in% c(
      "Police and Criminal Evidence Act 1984 (section 1)", 
      "Criminal Justice and Public Order Act 1994 (section 60)"
    ),
    object_of_search %in% 
      c("offensive weapons", "anything to threaten or harm anyone"),
    year_month >= yearmonth(ymd("2018-06-01"))
  ) %>% 
  count(bcu, legislation, year_month)

weapon_search_counts <- weapon_searches_by_month %>% 
  filter(bcu == report_bcu) %>% 
  group_by(legislation) %>% 
  mutate(
    year_month = as_date(year_month),
    diff = n - lag(n),
    diff_perc = diff / lag(n)
  ) %>% 
  ungroup()

weapon_search_prop <- weapon_searches_by_month %>% 
  filter(as_date(year_month) >= date_start) %>% 
  count(bcu, legislation, wt = n) %>% 
  group_by(bcu) %>% 
  mutate(prop = n / sum(n)) %>% 
  ungroup() %>% 
  filter(
    legislation == "Criminal Justice and Public Order Act 1994 (section 60)"
  ) %>% 
  mutate(
    prop_rank = min_rank(desc(prop)),
    rank_text = case_when(
      prop_rank == 1 ~ "the highest proportion of all",
      prop_rank == 2 ~ "the second highest proportion of all",
      prop_rank == n() ~ "the lowest proportion of all",
      prop_rank == n() - 1 ~ "the second lowest proportion of all",
      prop > mean(prop) + 5 ~ "higher than the proportion in most",
      prop < mean(prop) - 5 ~ "lower than the proportion in most",
      TRUE ~ "similar to other"
    )
  ) %>% 
  filter(bcu == report_bcu) %>%
  pluck("rank_text", 1)

weapon_search_annual_counts <- weapon_search_counts %>% 
  filter(year_month >= date_start) %>% 
  count(legislation, wt = n) %>% 
  mutate(prop = n / sum(n))
  
weapon_search_anomolies <- weapon_search_counts %>% 
  group_by(legislation) %>% 
  nest() %>% 
  mutate(
    anomalies = map(data, timetk::tk_anomaly_diagnostics, 
                    .date_var = year_month, .value = n)
  ) %>% 
  unnest(cols = anomalies)

weapon_search_trends <- weapon_search_counts %>% 
  filter(year_month >= max(year_month) - months(11)) %>% 
  group_by(legislation) %>% 
  arrange(year_month) %>% 
  mutate(
    change = n / first(n),
    year_month = as_date(year_month)
  ) %>% 
  ungroup() %>% 
  as_tsibble(key = legislation, index = year_month) %>% 
  model(lm = fable::TSLM(change ~ trend())) %>% 
  mutate(coefs = map(lm, broom::tidy)) %>% 
  unnest(cols = c(coefs)) %>% 
  filter(term == "trend()")

weapon_search_object_text <- ifelse(
  pull(filter(weapon_search_annual_counts, legislation == "Criminal Justice and Public Order Act 1994 (section 60)"), n) > 0,
  str_glue(
    ", with the remaining ", 
    percent(pull(filter(weapon_search_annual_counts, legislation == "Criminal Justice and Public Order Act 1994 (section 60)"), prop)),
    " (", 
    comma(pull(filter(weapon_search_annual_counts, legislation == "Criminal Justice and Public Order Act 1994 (section 60)"), n)),
    " searches", 
    ifelse(
      pull(filter(weapon_search_annual_counts, legislation == "Criminal Justice and Public Order Act 1994 (section 60)"), n) > 52,
      str_glue(
        ", or about ", 
        comma(pull(filter(weapon_search_annual_counts, legislation == "Criminal Justice and Public Order Act 1994 (section 60)"), n) / 52, accuracy = 1), 
        " per week"
      ), 
      ""
    ), 
    ") were conducted without the need for suspicion based on authorisations ",
    "under CJPOA section 60. Police do not publish any information about ",
    "authorisations made under section 60 so it is difficult to track any ",
    "patterns or trends, although section-60 searches are typically higher in ",
    "August due to the Notting Hill Carnival, which was cancelled in 2020"
  ),
  ""
)
```



Police can search people for weapons using two different legal powers. Searches under [section 1 of the Police and Criminal Evidence Act 1984](https://www.legislation.gov.uk/ukpga/1984/60/section/1) (PACE) require the officer to have "reasonable grounds for suspecting" that the person is carrying an offensive weapon or other prohibited item. Conversely, officers can search people under [section 60 of the Criminal Justice and Public Order Act 1994](https://www.legislation.gov.uk/ukpga/1994/33/section/60) (CJPOA) without having any reason to think the person has a weapon, as long as a more-senior officer believes "incidents involving serious violence may take place" in the area. These 'section 60' searches are particularly controversial because they allow officers to search *anyone* in an area, even if there is no reason to think they have a weapon in their possession. Between `r report_between`, `r percent(pull(filter(weapon_search_annual_counts, legislation == "Police and Criminal Evidence Act 1984 (section 1)"), prop))` of weapons searches in `r report_bcu` BCU were based on reasonable suspicion under PACE section 1`r weapon_search_object_text`. The proportion of weapon searches in the `r report_bcu` BCU that were conducted without the need for reasonable suspicion was `r weapon_search_prop` Metropolitan Police BCUs.



(ref:chart-trend-weapons) Change in number of searches for weapons, `r format(min(stops$date), '%B %Y')` to `r format(max(stops$date), '%B %Y')`

```{r chart-trend-weapons, fig.asp=0.5, fig.cap="(ref:chart-trend-weapons)", fig.pos="h"}
weapon_search_chart_data <- weapon_search_anomolies %>% 
  group_by(legislation, anomaly) %>% 
  mutate(
    anomaly_rank = min_rank(desc(abs(remainder) / observed)),
    legislation = recode_factor(
      legislation,
      "Police and Criminal Evidence Act 1984 (section 1)" = 
        "searches under PACE s. 1\n(based on reasonable suspicion)", 
      "Criminal Justice and Public Order Act 1994 (section 60)" = 
        "searches under CJPOA s. 60\n(based on authorisation)"
    )
  )

chart_trend_weapons <- ggplot(
  weapon_search_chart_data, 
  aes(year_month, observed, colour = legislation)
) +
  geom_segment(aes(xend = year_month, yend = 1), size = 0.25, 
               colour = "grey70") +
  ggrepel::geom_label_repel(
    aes(label = format(year_month, "%b %Y")),
    data = filter(weapon_search_chart_data, anomaly == "Yes", anomaly_rank <= 4),
    box.padding = unit(1, "lines"),
    # direction = "x",
    fill = rgb(1, 1, 1, 0.5),
    force = 10,
    label.size = NA,
    size = chart_elements$label_text_size
  ) +
  geom_point(
    data = filter(weapon_search_chart_data, anomaly == "Yes", anomaly_rank <= 4),
    size = 3, 
    shape = 21, 
    fill = "white", 
    show.legend = FALSE
  ) +
  geom_point(size = 0.75) +
  geom_smooth(
    method = "loess", 
    formula = "y ~ x", 
    se = FALSE, 
    data = filter(weapon_search_chart_data, anomaly == "No"),
    na.rm = TRUE
  ) +
  scale_x_date(
    date_breaks = "6 months", 
    date_labels = "%b '%y", 
    expand = expansion(mult = c(0.025, 0.025))
  ) +
  scale_y_continuous(
    labels = comma_format(), 
    limits = c(0, NA), 
    expand = expansion(mult = c(0, 0.05)), 
    position = "right"
  ) +
  scale_colour_manual(
    values = c(ucl_colours_list[["Light Red"]], 
               ucl_colours_list[["Bright Pink"]])
  ) +
  facet_grid(
    cols = vars(legislation), 
    scales = "free"
  ) +
  labs(
    caption = str_glue(
      "highlighted months are anomalies with unusually high/low numbers of ",
      "stops"
    ),
    x = NULL, 
    y = "number of searches"
  ) +
  theme_stop_search() +
  theme(
    axis.title.y = element_text(hjust = 0),
    legend.position = "none"
  )

# save_chart(
#   chart_trend_weapons, 
#   "04_trend_weapons",
#   str_glue(
#     "Change in number of searches for weapons, ",
#     "{format(min(stops$date), '%B %Y')} to {format(max(stops$date), '%B %Y')}"
#   )
# )

chart_trend_weapons
```



```{r}
# SECTION 1
weapon_trend_s1 <- weapon_search_trends %>% 
  filter(legislation == "Police and Criminal Evidence Act 1984 (section 1)") %>% 
  mutate(text = ifelse(
    p.value < 0.05,
    str_glue(
      ifelse(estimate > 0, "increased", "decreased"), " by about ",
      percent(abs(median(pull(filter(weapon_search_counts, legislation == "Police and Criminal Evidence Act 1984 (section 1)", year_month >= max(year_month) - months(11)), diff_perc)))),
      " per month on average"
    ),
    "not shown a significant increasing or decreasing trend"
  )) %>% pull(text)

weapon_previous_anomalies_s1 <- weapon_search_anomolies %>% 
  filter(
    anomaly == "Yes", 
    legislation == "Police and Criminal Evidence Act 1984 (section 1)"
  ) %>% 
  mutate(high = remainder > 0) %>% 
  {
    
    anm <- case_when(
      sum(.$high) > 0 & sum(!.$high) > 0 ~ str_glue(
        "anomalously high in ",
        "{vector_to_text(format(.$year_month[.$high], '%B %Y'))} ",
        "but anomalously low in ",
        "{vector_to_text(format(.$year_month[!.$high], '%B %Y'))}"
      ),
      sum(.$high) > 0 ~ str_glue(
        "anomalously high in ",
        "{vector_to_text(format(.$year_month[.$high], '%B %Y'))}"
      ),
      sum(!.$high) > 0 ~ str_glue(
        "anomalously low in ",
        "{vector_to_text(format(.$year_month[!.$high], '%B %Y'))}"
      ),
      TRUE ~ ""
    )
    
    ifelse(
      anm != "", 
      str_glue("In comparison to that trend, the number of these searches was {anm}."),
      ""
    )
    
  }


# SECTION 60
weapon_trend_s60 <- weapon_search_trends %>% 
  filter(legislation == "Criminal Justice and Public Order Act 1994 (section 60)") %>% 
  mutate(text = ifelse(
    p.value < 0.05,
    str_glue(
      ifelse(estimate > 0, "increased", "decreased"), " by about ",
      percent(abs(median(pull(filter(weapon_search_counts, legislation == "Criminal Justice and Public Order Act 1994 (section 60)", year_month >= max(year_month) - months(11)), diff_perc)))),
      " per month on average"
    ),
    "not shown a significant increasing or decreasing trend"
  )) %>% pull(text)

weapon_previous_anomalies_s60 <- weapon_search_anomolies %>% 
  filter(
    anomaly == "Yes", 
    legislation == "Criminal Justice and Public Order Act 1994 (section 60)"
  ) %>% 
  mutate(high = remainder > 0) %>% 
  {
    
    anm <- case_when(
      sum(.$high) > 0 & sum(!.$high) > 0 ~ str_glue(
        "anomalously high in ",
        "{vector_to_text(format(.$year_month[.$high], '%B %Y'))} ",
        "but anomalously low in ",
        "{vector_to_text(format(.$year_month[!.$high], '%B %Y'))}"
      ),
      sum(.$high) > 0 ~ str_glue(
        "anomalously high in ",
        "{vector_to_text(format(.$year_month[.$high], '%B %Y'))}"
      ),
      sum(!.$high) > 0 ~ str_glue(
        "anomalously low in ",
        "{vector_to_text(format(.$year_month[!.$high], '%B %Y'))}"
      ),
      TRUE ~ ""
    )
    
    ifelse(
      anm != "", 
      str_glue(", with searches having been {anm}."),
      ""
    )
    
  }
```



Searches based on reasonable suspicion the person being searched is carrying a weapon have `r weapon_trend_s1` over the past 12 months (Figure \@ref(fig:chart-trend-weapons)). `r weapon_previous_anomalies_s1`
No-suspicion searches under section 60 have `r weapon_trend_s60` over the past 12 months`r weapon_previous_anomalies_s60` The number of searches under section 60 is often higher in August because of searches associated with the Notting Hill Carnival, even in other parts of London.



# Who do police search?

```{r}
young_people_search_text <- age_counts %>% 
  mutate(age_range = recode(
    age_range, 
    "under 10" = "under 18", 
    "10-17" = "under 18", 
    "25-34" = "over 24", 
    "over 34" = "over 24"
  )) %>% 
  count(bcu, age_range, wt = n) %>% 
  pivot_wider(names_from = "age_range", values_from = "n") %>% 
  adorn_totals() %>% 
  adorn_percentages() %>% 
  select(bcu, under_18 = `under 18`) %>% 
  mutate(london = last(under_18)) %>% 
  filter(bcu != "Total") %>% 
  mutate(
    diff = under_18 - london, 
    rank = min_rank(desc(under_18))
  ) %>% 
  filter(bcu == report_bcu) %>% 
  rowwise() %>% 
  mutate(text = str_glue(
    "in the {bcu} BCU, ", percent(under_18, accuracy = 1), 
    " were aged under 18 -- ", 
    case_when(
      rank == 1 ~ "the highest proportion in London and ", 
      rank == 2 ~ "the second-highest proportion in London and ",
      rank == n() ~ "the lowest proportion in London and ",
      rank == n() - 1 ~ "the second-lowest proportion in London and ",
      TRUE ~ ""
    ), 
    case_when(
      diff > 0.02 ~ "higher than",
      diff < -0.02 ~ "lower than than",
      TRUE ~ "similar to"
    ),
    " the ", percent(london, accuracy = 1), " in London as a whole"
  )) %>% 
  pluck("text")
```

Of the `r comma(pull(count(filter(person_stops, date >= date_start, bcu == report_bcu)), n))` searches of pedestrians and vehicle occupants in the `r report_bcu` BCU from `r report_period`, **`r percent(pull(filter(adorn_percentages(count(filter(person_stops, bcu == report_bcu, gender %in% c("female", "male"), date >= date_start), gender), denominator = "col"), gender == "male"), n))` were searches of men or boys**, compared to `r percent(pull(filter(adorn_percentages(count(filter(person_stops, gender %in% c("female", "male"), date >= date_start), gender), denominator = "col"), gender == "male"), n))` of searches in London as a whole. Of all people searched `r young_people_search_text`.

The self-defined ethnicity of the person searched was known for `r percent(1 - pull(filter(sde_counts, is.na(sde_group), bcu == report_bcu), percent))` of searches, of which `r percent(pull(slice(filter(sde_counts, !is.na(sde_group), bcu == report_bcu), 1), valid_percent))` of people described themselves as `r pull(slice(filter(sde_counts, !is.na(sde_group), bcu == report_bcu), 1), sde_group)`, `r percent(pull(slice(filter(sde_counts, !is.na(sde_group), bcu == report_bcu), 2), valid_percent))` as `r pull(slice(filter(sde_counts, !is.na(sde_group), bcu == report_bcu), 2), sde_group)` and `r percent(pull(slice(filter(sde_counts, !is.na(sde_group), bcu == report_bcu), 3), valid_percent))` as `r pull(slice(filter(sde_counts, !is.na(sde_group), bcu == report_bcu), 3), sde_group)`.

**Search rates vary hugely across different groups**. Of the `r nrow(filter(stops_disparity, bcu == report_bcu))` combinations of sex, age and self-defined ethnicity present in the search data, `r nrow(filter(stops_disparity, bcu == report_bcu, search_rate > pluck(filter(overall_search_rate, bcu == report_bcu), "rate")))` groups were searched at a higher rate than the rate for the population as a whole (Figure \@ref(fig:chart-disparity)). While disparity between ethnic groups has generated much comment, `r ifelse(length(pluck(filter(stops_model, bcu == report_bcu), 'data', 1)) > 0, str_glue("{knitr::combine_words(pluck(filter(stops_model, bcu == report_bcu), 'data', 1))} are more-powerful predictors of a group having a higher search rate than that group being non-white"), "there are also disparities between age groups and sexes")`. The reasons for these differences are likely to be complex: many types of offending are concentrated among some groups (particularly young men) as well as in some neighbourhoods, and there are [longstanding issues of bias and stereotyping among police and in society](https://www.bbc.co.uk/news/uk-47300343). There is also an interaction between factors such as deprivation and the amount of time people spend in public (where almost-all searches occur). There is no way to know from the data analysed here what combination of these factors drives the disparities in search rates.



(ref:chart-disparity) Search rates for different demographic groups, `r report_period`

```{r chart-disparity, fig.asp=0.5, fig.cap="(ref:chart-disparity)", fig.pos="h"}
search_rates_above_average <- stops_disparity %>% 
  filter(
    bcu == report_bcu,
    search_rate > pluck(filter(overall_search_rate, bcu == report_bcu), "rate")
  ) %>% 
  pluck("group")

chart_disparity_data <- stops_disparity %>% 
  arrange(desc(search_rate)) %>% 
  filter(
    bcu %in% c(report_bcu, "London"),
    group %in% search_rates_above_average
  ) %>% 
  add_row(
    bcu = report_bcu,
    group = "**all people**", 
    search_rate = pluck(filter(overall_search_rate, bcu == report_bcu), "rate")
  ) %>% 
  add_row(
    bcu = "London",
    group = "**all people**", 
    search_rate = pluck(filter(overall_search_rate, bcu == "London"), "rate")
  ) %>% 
  mutate(
    group = fct_relevel(fct_reorder(group, search_rate), "**all people**", 
                        after = Inf)
  )

chart_disparity <- ggplot(
    chart_disparity_data,
    aes(search_rate, group, fill = bcu == report_bcu, group = bcu)
  ) +
  geom_col(position = "dodge") +
  geom_vline(
    aes(xintercept = x),
    data = tibble(
      x = seq(
        0, 
        ceiling(max(chart_disparity_data$search_rate)), 
        by = 10
      )
    ),
    colour = "white",
    alpha = 0.75
  ) +
  scale_x_continuous(expand = c(0, 0.05), n.breaks = 8) +
  scale_fill_manual(
    values = c(
      `TRUE` = ucl_colours_list[["Dark Blue"]], 
      `FALSE` = ucl_colours_list[["Light Blue"]]
    ),
    labels = c(`TRUE` = str_glue("{report_bcu} BCU"), `FALSE` = "London")
  ) +
  labs(
    x = "searches per 1,000 people",
    fill = NULL
  ) +
  theme_stop_search() +
  theme(
    axis.text.y = element_markdown(),
    axis.ticks.y = element_blank(),
    axis.title.y = element_blank(),
    legend.justification = c(1, 0),
    legend.position = c(1, 0),
    panel.grid.major.y = element_blank(),
    panel.grid.minor = element_blank()
  )

# save_chart(
#   chart_disparity, 
#   "05_disparity",
#   str_glue("Search rates for different demographic groups, {report_period}"),
# )

chart_disparity
```



```{r}
stops_disparity_object_chart <- stops_disparity_object %>%
  filter(bcu == report_bcu) %>% 
  group_by(object) %>%
  mutate(
    rel_search_rate = search_rate / (sum(searches) / (sum(people) / 1000))
  ) %>%
  ungroup() %>%
  arrange(desc(rel_search_rate)) %>%
  mutate(
    object_label = recode(
      object,
      "weapons (based on authorisation)" = "weapons (s. 60)",
      "weapons (based on reasonable suspicion)" = "weapons (s. 1)"
    ),
    group = str_glue("{group}"),
    group = fct_reorder(group, rel_search_rate)
  )

disparity_groups_text <- stops_disparity_object_chart %>% 
  arrange(desc(rel_search_rate)) %>% 
  group_by(object) %>% 
  slice(1) %>% 
  ungroup() %>% 
  {
    
    text <- case_when(
      length(unique(.$group)) == 1 ~ 
        str_glue(
          "all five of the main types of search for {.$age_label[1]} aged ",
          "{.$age_range[1]} who identified as {.$ethnic_group[1]}"
        ),
      length(unique(.$sex)) == 1 & length(unique(.$ethnic_group)) == 1 ~ 
        str_glue(
          "all five of the main types of search for {.$age_label[1]} who ",
          "identified as {.$ethnic_group[1]}"
        ),
      length(unique(.$sex)) == 1 & length(unique(.$age_range)) == 1 ~ 
        str_glue(
          "all five of the main types of search for {.$age_label[1]} aged ",
          "{.$age_range[1]}"
        ),
      pluck(count(., age_range, ethnic_group, sex, sort = TRUE), "n", 1) > 2 ~
        str_glue(
          "{number_to_text(pluck(arrange(count(., age_range, ethnic_group, sex), desc(n)), 'n', 1))} ",
          "of the five of the main types of search for {.$age_label[1]} aged ",
          "{.$age_range[1]} who identified as {.$ethnic_group[1]}"
        ),
      pluck(count(., ethnic_group, sex, sort = TRUE), "n", 1) > 2 ~
        str_glue(
          "{number_to_text(pluck(arrange(count(., age_range, ethnic_group, sex), desc(n)), 'n', 1))} ",
          "of the five of the main types of search for {.$age_label[1]} ",
          "who identified as {.$ethnic_group[1]}"
        ),
      pluck(count(., age_range, sex, sort = TRUE), "n", 1) > 2 ~
        str_glue(
          "{number_to_text(pluck(arrange(count(., age_range, ethnic_group, sex), desc(n)), 'n', 1))} ",
          "of the five of the main types of search for {.$age_label[1]} aged ",
          "{.$age_range[1]}"
        ),
      TRUE ~ ""
    )
    
    ifelse(
      str_length(text) > 0,
      str_glue("Of the {number(length(unique(stops_disparity_object$sex)) * length(unique(stops_disparity_object$age_range)) * length(unique(stops_disparity_object$ethnic_group)))} combinations of age, ethnic-group and sex present in the data, the rate of searches in the {report_bcu} BCU was highest for {text}."),
      ""
    )
    
  }

highest_object_disparity <- str_glue(
  "{stops_disparity_object_chart$object_label[1]}, for which ",
  "{stops_disparity_object_chart$age_label[1]} aged ",
  "{stops_disparity_object_chart$age_range[1]} identifying as ", 
  "{stops_disparity_object_chart$ethnic_group[1]} were ",
  "{number(stops_disparity_object_chart$rel_search_rate[1])} ",
  "times more likely to be searched than the population at large"
)
```



In comparison to the population of the `r report_bcu` BCU as a whole, `r str_remove_all(pluck(slice_max(filter(stops_disparity, bcu == report_bcu), search_rate), "group"), "\\*\\*")` (the group with the highest search rate) were on-average `r number(pluck(slice_max(filter(stops_disparity, bcu == report_bcu), search_rate), "search_rate") / pluck(filter(overall_search_rate, bcu == report_bcu), "rate"))` times more likely to be stopped and searched. Disparities in search rates also vary according to the type of search. Disparity is highest in searches for `r highest_object_disparity`. `r disparity_groups_text` It is important to note that these disparity ratios only represent _average_ search rates for different groups -- they do not reflect the individual experience of everyone in each group. It is likely that a small number of people in each group are being searched repeatedly while others are searched far less often, but since police do not publish data on repeated searches it is difficult to know how this affects overall search rates.



# How often do police find items during searches?

The purpose of stop and search is to "enable officers to allay or confirm suspicions about individuals without exercising their power of arrest" ([PACE Code A, paragraph 1.4](https://www.gov.uk/guidance/police-and-criminal-evidence-act-1984-pace-codes-of-practice)). As such, a search that does not find what is being searched for can be considered successful if it prevents an innocent person being arrested and a police officer being taken off the street unnecessarily. There is not necessarily an optimal proportion of searches that should result in the officer finding what they are looking for. Measuring outcomes is also difficult: officers may have legitimate grounds to search a group of people (e.g. all the occupants in a vehicle believed to contain a firearm) when only one person has contraband in their possession. Nevertheless, all searches are an "intrusion on the liberty of the person" (PACE Code A, paragraph 1.2) and high proportions of searches that do not find anything may indicate that searches are not well targeted.

The data released by the Home Office do not specify whether or not the item police were looking for was found during a search. Instead, we can measure whether a search resulted in some formal criminal-justice process such as an arrest. This is not a perfect measure of whether an item was found during a search, because a person might be arrested for some other reason (for example because there was an outstanding warrant for their arrest) or contraband might be found but police deal with it informally. Nevertheless, this is the least-worst measure of search outcomes that is currently available.

```{r positive results}
search_result_counts <- stops %>% 
  filter(!object %in% c("other", "unknown"), outcome != "unknown") %>% 
  mutate(
    object = case_when(
      object == "weapons" & 
        legislation == "Police and Criminal Evidence Act 1984 (section 1)" ~ 
        "weapons (based on reasonable suspicion)",
      object == "weapons" & 
        legislation == "Criminal Justice and Public Order Act 1994 (section 60)" ~ 
        "weapons (based on authorisation)",
      object == "weapons" ~ "unknown",
      TRUE ~ object
    ),
    positive = outcome != "no further action",
    year_month = as_date(year_month)
    # year_quarter = as_date(yearquarter(year_month))
  ) %>% 
  {
    x <- .
    bind_rows(
      count(filter(x, bcu == report_bcu), bcu, object, year_month, positive),
      mutate(count(x, object, year_month, positive), bcu = "London")
    )
  } %>% 
  group_by(bcu, year_month, object) %>%
  mutate(prop = n / sum(n)) %>%
  ungroup()

search_result_overall_counts <- search_result_counts %>% 
  count(bcu, year_month, positive, wt = n) %>% 
  mutate(prop = n / sum(n)) %>% 
  group_by(bcu, year_month) %>% 
  mutate(prop = n / sum(n)) %>% 
  ungroup()

# Calculate overall hit rate for the past 12 months
hit_rate_last_year <- search_result_overall_counts %>% 
  filter(as_date(year_month) >= date_start) %>% 
  count(bcu, positive, wt = n) %>% 
  group_by(bcu) %>% 
  mutate(prop = n / sum(n)) %>% 
  ungroup() %>% 
  filter(positive) %>% 
  select(bcu, prop) %>% 
  deframe()

# Arrange search objects in descending order of mean hit rate
search_result_order <- search_result_counts %>% 
  filter(bcu == report_bcu, positive, year_month >= date_start) %>% 
  group_by(object) %>% 
  summarise(count = median(n), prop = median(prop), .groups = "drop") %>% 
  arrange(desc(prop))

# Calculate linear trend in hit rate over the past 12 months
search_result_trends <- search_result_counts %>% 
  filter(positive, as_date(year_month) >= date_start, bcu == report_bcu) %>% 
  as_tsibble(key = object, index = year_month) %>% 
  model(lm = fable::TSLM(prop ~ trend())) %>% 
  mutate(coefs = map(lm, broom::tidy)) %>% 
  unnest(cols = c(coefs)) %>% 
  filter(term == "trend()", p.value < 0.05)

# Explain whether there have been significant increases/decreases in hit rates
# for different search types over the past 12 months
search_result_trend_text <- case_when(
  # Some increased and some decreased
  nrow(filter(search_result_trends, estimate > 0)) > 0 
  & nrow(filter(search_result_trends, estimate < 0)) > 0 ~ 
    str_glue(
      "for ", 
      vector_to_text(pull(filter(search_result_trends, estimate > 0), object)), 
      " resulting in a formal outcome increased while the proportion of ", 
      "searches for ", 
      vector_to_text(pull(filter(search_result_trends, estimate < 0), object)), 
      " resulting in a formal outcome decreased"
    ), 
  # Some increased and none decreased
  nrow(filter(search_result_trends, estimate > 0)) > 0 ~ 
    str_glue(
      "for ", 
      vector_to_text(pull(filter(search_result_trends, estimate > 0), object)), 
      " resulting in a formal outcome have", 
      ifelse(nrow(filter(search_result_trends, estimate > 0)) > 2, " all ", " "), 
      "increased"
    ), 
  # Some decreased and none increased
  nrow(filter(search_result_trends, estimate < 0)) > 0 ~ 
    str_glue(
      "for ", 
      vector_to_text(pull(filter(search_result_trends, estimate < 0), object)), 
      " resulting in a formal outcome have", 
      ifelse(nrow(filter(search_result_trends, estimate < 0)) > 2, " all ", " "), 
      "decreased"
    ), 
  # No significant increases or decreases
  TRUE ~ "leading to a formal outcome has not shown any consistent increasing or decreasing trend"
)

results_by_type <- stops %>% 
  mutate(
    object = case_when(
      object == "weapons" & 
        legislation == "Police and Criminal Evidence Act 1984 (section 1)" ~ 
        "weapons (based on reasonable suspicion)",
      object == "weapons" & 
        legislation == "Criminal Justice and Public Order Act 1994 (section 60)" ~ 
        "weapons (based on authorisation)",
      object == "weapons" ~ "unknown",
      TRUE ~ object
    ),
    outcome = fct_rev(recode(
      outcome, 
      "community/local resolution" = "community resolution"
    ))
  ) %>% 
  filter(
    bcu == report_bcu,
    !object %in% c("other", "unknown"), 
    !outcome %in% c("no further action", "unknown", "drugs warning", "caution"), 
    date >= date_start
  ) %>% 
  count(object, outcome) %>% 
  group_by(object) %>% 
  mutate(prop = n / sum(n)) %>% 
  ungroup()

most_common_outcome <- stops %>% 
  filter(bcu == report_bcu, !outcome %in% c("no further action", "unknown")) %>% 
  count(outcome, sort = TRUE) %>% 
  head(1) %>% 
  pull(outcome) %>% 
  as.character()

invalid_outcomes_text <- results_by_type %>% 
  filter(
    n >= 10, 
    object %in% c(
      "firearms", 
      "weapons (based on authorisation)", 
      "weapons (based on reasonable suspicion)"
    ), 
    outcome == "fixed penalty"
  ) %>% 
  arrange(desc(prop)) %>% 
  mutate(
    text = str_glue("{percent(prop)} of formal outcomes to searches for {object}")
  ) %>%
  pluck("text") %>% 
  knitr::combine_words(oxford_comma = FALSE) %>% 
  {
    ifelse(
      length(.) > 0, 
      str_glue(
        "The outcomes of some searches suggest that the outcome does not ",
        "relate to the type of contraband that police were looking for. For ",
        "example, fixed penalties are not a legally available option for ",
        "dealing with weapons or firearms offences, but ", 
        ., 
        " were fixed penalties. This suggests that some weapons or firearms ",
        "searches result in police not finding weapons but discovering ",
        "more-minor offences such as cannabis possession."
      ), 
      ""
    )
  }

lowest_search_prop <- search_result_counts %>% 
  filter(
    bcu == "London", 
    object == tail(search_result_order$object, 1), 
    year_month >= date_start
  ) %>% 
  count(positive, wt = n) %>% 
  mutate(prop = n / sum(n)) %>% 
  filter(positive) %>% 
  pluck("prop") %>% 
  {
    x <- .
    str_glue(
      compare_props(x, tail(search_result_order$prop, 1)),
      " the ", 
      percent(1 - x),
      " of such stops resulting in no further action in London as a whole"
    )
  }
```



(ref:chart-results) Change in proportion of searches with a formal outcome, `r format(min(stops$date), '%B %Y')` to `r format(max(stops$date), '%B %Y')`

```{r chart-results, fig.asp=0.5, fig.cap="(ref:chart-results)", fig.pos="h"}
chart_hit_rate <- search_result_counts %>% 
  filter(
    positive, 
    object %in% pluck(search_result_order, "object"), 
    year_month >= ymd("2018-04-01")
  ) %>%
  mutate(
    bcu = bcu == "London",
    object = fct_relevel(object, pull(filter(search_result_order, count > 100), object)),
  ) %>% 
  group_by(bcu, object) %>% 
  mutate(
    prop_ma = slider::slide_dbl(prop, mean, .before = 5, .complete = TRUE)
  ) %>% 
  ungroup() %>% 
  ggplot(aes(year_month, prop_ma, colour = bcu, group = bcu)) +
  # geom_segment(aes(xend = year_month, yend = 0), size = 0.25, 
  #              colour = "grey70") +
  # geom_point(size = 0.75, alpha = 0.75) +
  # geom_smooth(method = "loess", formula = "y ~ x", se = FALSE) +
  geom_line(na.rm = TRUE, size = 1) +
  scale_x_date(date_breaks = "1 year", date_labels = "'%y",
               expand = expansion(mult = c(0.025, 0.025))) +
  scale_y_continuous(labels = percent_format(accuracy = 1),
                     limits = c(0, NA),
                     expand = expansion(mult = c(0, 0.025)), 
                     position = "right") +
  scale_colour_manual(
    values = c(
      `TRUE` = ucl_colours_list[["Dark Blue"]], 
      `FALSE` = ucl_colours_list[["Light Blue"]]
    ),
    labels = c(`TRUE` = str_glue("{report_bcu} BCU"), `FALSE` = "London")
  ) +
  facet_grid(
    cols = vars(object),
    labeller = as_labeller(function (string) {
      str_wrap(paste("searches for", string), 18)
    })
  ) +
  labs(
    x = NULL, 
    y = "proportion resulting in a formal outcome",
    colour = NULL
  ) +
  theme_stop_search() +
  theme(
    axis.title.y = element_text(hjust = 0),
    legend.position = "bottom"
  )

# save_chart(
#   chart_hit_rate, 
#   "06_hit_rate",
#   str_glue(
#     "Change in proportion of searches with a formal outcome, ",
#     "{format(min(stops$date), '%B %Y')} to {format(max(stops$date), '%B %Y')}"
#   )
# )

chart_hit_rate
```



Overall, about `r percent(hit_rate_last_year[[report_bcu]])` of searches in the `r report_bcu` BCU between `r report_between` resulted in a formal criminal-justice outcome (`r knitr::combine_words(sort(as.character(unique(pluck(filter(stops, bcu == report_bcu, date >= date_start, !outcome %in% c("no further action", "unknown")), "outcome")))), and = " or ", oxford_comma = FALSE)`), while the remaining **`r percent(1 - hit_rate_last_year[[report_bcu]])` of searches resulted in no further action.** The proportion of stops in the `r report_bcu` BCU with a formal outcome was `r compare_props(hit_rate_last_year[[report_bcu]], hit_rate_last_year[["London"]])` the proportion (`r percent(hit_rate_last_year[["London"]])`) in London as a whole. Over the past year, searches for `r head(search_result_order$object, 1)` have been most likely to lead to a formal outcome (`r percent(head(search_result_order$prop, 1))`, `r compare_props(head(search_result_order$prop, 1), pluck(filter(adorn_percentages(count(filter(search_result_counts, bcu == "London", object == head(search_result_order$object, 1), year_month >= date_start), positive, wt = n), denominator = "col"), positive), "n"))` the `r percent(pluck(filter(adorn_percentages(count(filter(search_result_counts, bcu == "London", object == head(search_result_order$object, 1), year_month >= date_start), positive, wt = n), denominator = "col"), positive), "n"))` figure across London), while `r percent(1 - tail(search_result_order$prop, 1))` of searches for `r ifelse(tail(search_result_order$object, 1) == "weapons (based on authorisation)", "weapons under a section 60 authorisation", tail(search_result_order$object, 1))` resulted in no further action, `r lowest_search_prop`.

In the past 12 months, the proportion of searches `r search_result_trend_text` (Figure \@ref(fig:chart-results)). When a stop does result in formal action, the most common outcome is `r most_common_outcome` (used in `r percent(head(pull(janitor::adorn_percentages(count(filter(stops, bcu == report_bcu, !outcome %in% c("no further action", "unknown")), outcome, sort = TRUE), "col"), n), 1))` of cases with a formal outcome). However, which action police choose varies with the type of search: `r percent(pull(head(arrange(filter(results_by_type, outcome == most_common_outcome), desc(prop)), 1), prop))` of positive searches for `r pull(head(arrange(filter(results_by_type, outcome == most_common_outcome), desc(prop)), 1), object)` result in `r most_common_outcome`, compared to only `r percent(pull(tail(arrange(filter(results_by_type, outcome == most_common_outcome), desc(prop)), 1), prop))` of positive searches for `r pull(tail(arrange(filter(results_by_type, outcome == most_common_outcome), desc(prop)), 1), object)`. `r invalid_outcomes_text`



```{r outcomes by ethnicity}
stops_by_ethnicity <- stops %>% 
  separate(self_defined_ethnicity, c("ethnic_group", "ethnicity"), " - ") %>% 
  mutate(
    ethnic_group = str_extract(ethnic_group, "^\\w+"),
    formal_disposal = outcome != "no further action",
    object = case_when(
      object == "weapons" & 
        legislation == "Police and Criminal Evidence Act 1984 (section 1)" ~ 
        "weapons (based on reasonable suspicion)",
      object == "weapons" & 
        legislation == "Criminal Justice and Public Order Act 1994 (section 60)" ~ 
        "weapons (based on authorisation)",
      object == "weapons" ~ "unknown",
      TRUE ~ object
    )
  ) %>% 
  filter(
    !is.na(ethnic_group),
    !object %in% c("other", "unknown"), 
    outcome != "unknown",
    as_date(year_month) >= date_start
  )

# Count stops by ethnicity and calculate proportions
outcomes_by_ethnicity <- bind_rows(
    count(filter(stops_by_ethnicity, bcu == report_bcu), bcu, object, formal_disposal, ethnic_group),
    mutate(count(stops_by_ethnicity, object, formal_disposal, ethnic_group), bcu = "London")
) %>% 
  group_by(bcu, object, ethnic_group) %>% 
  mutate(prop = n / sum(n)) %>% 
  ungroup() %>% 
  filter(formal_disposal)

# Find order of ethnicities by hit rate for most-frequent search object
outcomes_by_ethnicity_order <- outcomes_by_ethnicity %>% 
  filter(
    bcu == report_bcu,
    object == pluck(slice_max(filter(total_searches_by_object, bcu == report_bcu), "n"), "object")
  ) %>% 
  arrange(prop) %>% 
  pull(ethnic_group)

# Model whether the hit rate for each search object varies between ethnicities
outcomes_by_ethnicity_model <- stops_by_ethnicity %>% 
  filter(bcu == report_bcu) %>% 
  mutate(ethnic_group = fct_relevel(ethnic_group, "White")) %>% 
  nest(data = -object) %>% 
  mutate(model = map(data, function (x) {
    broom::tidy(glm(formal_disposal ~ ethnic_group, data = x))
  })) %>% 
  select(object, model) %>% 
  unnest(cols = model) %>% 
  filter(term %in% c("ethnic_groupAsian", "ethnic_groupBlack", "ethnic_groupMixed")) %>% 
  mutate(
    odds_ratio = exp(estimate),
    sig = p.value < 0.05 & !between(odds_ratio, 0.95, 1.05),
    search_type = str_glue(
      "searches of {str_remove(term, '^ethnic_group')} people for {object}"
    ),
    term = str_remove(term, "^ethnic_group"),
    diff_type = ifelse(
      odds_ratio > 1, 
      str_glue("higher for {search_type}"), 
      str_glue("lower for {search_type}")
    )
  ) %>% 
  arrange(term)

# Generate text to summarise these models
outcomes_by_ethnicity_model_text <- ifelse(
  sum(outcomes_by_ethnicity_model$sig) / length(outcomes_by_ethnicity_model$sig) > 0.5, 
  str_glue(
    "Just as some ethnic groups are more likely to be stopped than others, ",
    "the probability of a stop resulting in a formal criminal-justice outcome ",
    "also varies by ethnicity: over the past 12 months, the probability of a ",
    "formal outcome to a search is ",
    to_text(pull(
      filter(outcomes_by_ethnicity_model, sig), 
      diff_type
    ))
  ), 
  str_glue(
    "While the rate of searches varies between ethnic groups, the probability ",
    "of a search resulting in a formal criminal-justice outcome is broadly ",
    "the same across ethnicities â€“ over the past six months, ", 
    ifelse(
      sum(outcomes_by_ethnicity_model$sig) > 0, 
      str_glue(
        "the probability of a formal outcome to searches of Black, Asian or ",
        "Mixed-ethnicity people is only significantly different from the ",
        "probabilty of a formal outcome to searches of White people for ",
        to_text(pull(filter(outcomes_by_ethnicity_model, sig), search_type))
      ),
      str_glue(
        "the probability of a formal outcome to searches of Black, Asian or ",
        "Mixed-ethnicity people was not significantly different from the ",
        "probabilty of a formal outcome to searches of White people for any ",
        "of the main search types"
      )
    )
  )
)
```



`r outcomes_by_ethnicity_model_text` (Figure \@ref(fig:chart-outcomes-ethnicity)).



(ref:chart-outcomes-ethnicity) Proportion of searches resulting in a formal outcome, `r report_period`

```{r chart-outcomes-ethnicity, fig.asp=0.5, fig.cap="(ref:chart-outcomes-ethnicity)", fig.pos="h"}
chart_outcomes_ethnicity <- outcomes_by_ethnicity %>% 
  group_by(object) %>% 
  filter(min(n) >= 10) %>% 
  ungroup() %>% 
  mutate(
    align = ifelse(prop > max(prop) / 2, 1, 0),
    ethnic_group = fct_relevel(as.character(ethnic_group), 
                               outcomes_by_ethnicity_order),
    prop_label = percent(prop, accuracy = 1, prefix = " ", suffix = "% "),
    text_colour = prop > max(prop) / 2 & bcu == report_bcu
  ) %>% 
  ggplot(aes(
    prop, 
    ethnic_group, 
    alpha = bcu == "London",
    colour = text_colour, 
    fill = object, 
    group = bcu == "London", 
    hjust = align,
    label = prop_label
  )) +
  geom_col(alpha = 1, colour = NA, fill = "white", position = position_dodge(width = 0.9)) +
  geom_col(colour = NA, position = position_dodge(width = 0.9)) +
  geom_text(
    alpha = 1,
    position = position_dodge(width = 0.9), 
    size = chart_elements$label_text_size
  ) +
  scale_x_continuous(breaks = c(0, 0.1, 0.2), labels = percent_format()) +
  scale_alpha_manual(
    values = c(`FALSE` = 1, `TRUE` = 0.5),
    labels = c(`FALSE` = str_glue("{report_bcu} BCU"), `TRUE` = "London")
  ) +
  scale_colour_manual(
    values = c(`FALSE` = chart_elements$label_text_colour, `TRUE` = "white"),
    guide = guide_none()
  ) +
  scale_fill_manual(values = search_type_colours, guide = guide_none()) +
  facet_grid(cols = vars(object), labeller = label_wrap_gen(width = 16)) +
  labs(
    x = NULL,
    y = NULL,
    alpha = NULL
  ) +
  theme_stop_search() +
  theme(
    axis.ticks.y = element_blank(),
    legend.position = "bottom",
    panel.grid.major.x = element_line(),
    panel.grid.major.y = element_blank()
  )

# save_chart(
#   chart_outcomes_ethnicity, 
#   "07_chart_outcomes_ethnicity",
#   str_glue(
#     "Proportion of searches resulting in a formal outcome, ", 
#     "{ifelse(format(max(stops$year_month), '%Y') == format(as_date(max(stops$year_month)) - months(5), '%Y'), format(as_date(max(stops$year_month)) - months(5), '%B'), format(as_date(max(stops$year_month)) - months(5), '%B %Y'))}",
#     " to {format(max(stops$year_month), '%B %Y')}"
#   )
# )

chart_outcomes_ethnicity
```



# Where do stops happen?

```{r deprivation, include=FALSE}
# Find proportion of total stops that occur in the 50% most-deprived LSOAs
stops_by_deprivation <- stops_by_lsoa %>% 
  filter(bcu == report_bcu) %>% 
  count(lsoa_code, name = "searches") %>% 
  left_join(imd, by = "lsoa_code") %>% 
  mutate(imd_perc = ceiling(imd_perc * 100)) %>% 
  arrange(imd_perc) %>% 
  count(imd_perc, wt = searches, name = "searches") %>% 
  mutate(
    csum_searches = cumsum(searches),
    csum_searches = csum_searches / max(csum_searches)
  ) %>% 
  filter(imd_perc == 50) %>% 
  slice(1) %>% 
  pull(csum_searches)

# Find proportion of stops by type that occur in the 50% most-deprived LSOAs
stops_by_deprivation_object <- stops_by_lsoa %>% 
  filter(
    bcu == report_bcu,
    object %in% c("drugs", "firearms", "stolen goods", 
                  "weapons under section 1", "weapons under section 60")
  ) %>% 
  count(object, lsoa_code, name = "searches") %>% 
  left_join(imd, by = "lsoa_code") %>% 
  mutate(imd_perc = ceiling(imd_perc * 100)) %>% 
  arrange(imd_perc) %>% 
  count(object, imd_perc, wt = searches, name = "searches") %>% 
  group_by(object) %>% 
  mutate(
    csum_searches = cumsum(searches),
    csum_searches = csum_searches / max(csum_searches)
  ) %>% 
  filter(imd_perc == 50) %>% 
  slice(1) %>% 
  ungroup() %>% 
  arrange(desc(csum_searches))

# Construct description for concentration of stops by deprivation
stops_by_deprivation_text <- ifelse(
  stops_by_deprivation > 0.55, 
  str_glue(
    "Searches are also concentrated in deprived areas: ", 
    "{percent(stops_by_deprivation)} of searches took place in neighbourhoods ",
    "that were more deprived than the BCU average.", 
    ifelse(
      max(stops_by_deprivation_object$csum_searches) > stops_by_deprivation + 0.03, 
      str_glue(
        " In particular, ",
        "{percent(pull(slice(stops_by_deprivation_object, 1), csum_searches))}",
        " of searches for ",
        "{pull(slice(stops_by_deprivation_object, 1), object)} occurred in ",
        "the most-deprived half of neighbourhoods."
      ), 
      ""
    )
  ), 
  ""
)
```



```{r prepare hotspots, include=FALSE}
# Convert data to an SF object for plotting
stops_sf <- stops %>% 
  filter(!is.na(latitude), !is.na(longitude), date >= date_start) %>% 
  st_as_sf(coords = c("longitude", "latitude"), crs = 4326)

# Create buffered boundary for report BCU
map_area <- london_bcu %>% 
  filter(bcu == report_bcu) %>% 
  lwgeom::st_minimum_bounding_circle() %>% 
  # st_transform(27700) %>% 
  # st_buffer(500) %>% 
  st_transform(4326) %>%
  st_bbox() %>% 
  st_as_sfc() %>% 
  st_sf()

# Calculate grids of hexagonal cells (`cell_size` is width in metres, which
# requires the layers to be projected using the British National Grid)
grid_1km <- map_area %>% 
  st_transform(27700) %>% 
  create_grid_hexagonal(cell_size = 250) %>% 
  st_crop(london_outline) %>% 
  st_transform(4326) %>% 
  mutate(id = row_number())

# Count stops in each grid cell
grid_stops <- stops_sf %>% 
  st_join(grid_1km) %>% 
  as_tibble() %>% 
  count(id, name = "searches") %>% 
  full_join(grid_1km, by = "id") %>% 
  filter(!is.na(id)) %>% 
  mutate(searches = ifelse(searches == 0 | is.na(searches), NA, searches)) %>% 
  st_sf()

# Identify hotspot cells
grid_neighbours <- grid_1km %>% 
  st_transform(27700) %>% 
  st_centroid() %>% 
  st_coordinates() %>% 
  dnearneigh(0, 250 * 1.5) %>% 
  include.self()
grid_gi <- grid_stops %>% 
  replace_na(list(searches = 0)) %>% 
  pull(searches) %>% 
  localG(listw = nb2listw(grid_neighbours, style = "B"))
grid_stops_gi <- grid_stops %>% 
  add_column(gistar = grid_gi) %>% 
  mutate(
    # Convert the Z scores to p values
    pvalue = 2 * pnorm(-abs(as.numeric(grid_gi))),
    # Calculate if the p values are statistically significant, which by
    # convention is if p < 0.05, adjusting for multiple comparisons using 
    # p.adjustSP()
    significant = p.adjustSP(pvalue, grid_neighbours) < 0.05
  ) %>%
  select(-pvalue)

# Estimate density for grid cells
grid_kde <- stops_sf %>% 
  st_join(grid_1km) %>% 
  st_transform(27700) %>% 
  kde(band_width = 250 * 1.5, grid = st_transform(grid_1km, 27700)) %>% 
  st_drop_geometry() %>% 
  right_join(grid_stops_gi, by = "id") %>% 
  as_tibble() %>% 
  st_sf() %>% 
  st_intersection(st_transform(london_outline, 4326))

# Identify nearest station for hotspot cells
hotspot_labels <- grid_kde %>% 
  filter(significant) %>% 
  # Filter out cells that are outside the inner buffer, even though `grid_kde`
  # is already cropped to the bounding box of the outer buffer, so that only 
  # hotspots in or very close to the BCU area are labelled
  st_join(st_transform(filter(london_bcu, bcu == report_bcu), 4326)) %>% 
  filter(!is.na(bcu)) %>% 
  arrange(desc(kde_value)) %>% 
  mutate(rank = percent_rank(kde_value)) %>% 
  # Slice more rows than needed because some will be duplicates that are removed
  # later
  slice(1:50) %>% 
  st_centroid() %>% 
  st_transform(4326) %>% 
  mutate(
    coord_x = st_coordinates(.)[, 1], 
    coord_y = st_coordinates(.)[, 2],
    nearest_station_id = st_nearest_feature(., london_stations)
  ) %>% 
  left_join(
    st_drop_geometry(london_stations), 
    by = c("nearest_station_id" = "id")
  ) %>% 
  as_tibble() %>% 
  # Remove duplicate cells that have the same closest station
  distinct(name, .keep_all = TRUE) %>% 
  # Filter out cells with lower-than-median density
  filter(rank >= 0.5) %>% 
  slice(1:10) %>% 
  mutate(label = str_glue("{ordinal(row_number())}. {name}"))

hotspot_label_lims <- london_bcu %>% 
  filter(bcu == report_bcu) %>% 
  st_transform(4326) %>% 
  st_bbox()
```



Stop and search is geographically concentrated in some parts of the `r report_bcu` BCU: **half of searches between `r report_between` occurred in `r percent(pluck(filter(stop_concentration, bcu == report_bcu), "perc_rank", 1))` of neighbourhoods**. `r stops_by_deprivation_text`

`r report_bcu` BCU had the `r pluck(filter(searches_by_bcu, bcu == report_bcu), "rank_text", 1)` searches of the `r nrow(searches_by_bcu)` Metropolitan Police BCUs. We can identify the areas of the BCU with most searches by dividing it into a grid of equally-sized cells and mapping the density of searches in each grid cell (Figure \@ref(fig:chart-map)).

Of the `r comma(nrow(filter(searches_by_ward, bcu == report_bcu)))` local-authority wards in the `r report_bcu` BCU, the ward with the most searches between `r report_between` was `r pluck(filter(searches_by_ward, bcu == report_bcu), "ward", 1)` ward in `r pluck(filter(searches_by_ward, bcu == report_bcu), "borough", 1)` (Table \@ref(tab:table-ward)).



# A note on data

This report uses data published by the Home Office at [data.police.uk](https://data.police.uk/) under the [Open Government Licence version 3.0](https://www.nationalarchives.gov.uk/doc/open-government-licence/version/3/) for searches conducted by the Metropolitan Police Service or by British Transport Police at a location in `r report_bcu` BCU.

Search rates are calculated using [2020 estimates of the London population by age and ethnic group](https://data.london.gov.uk/dataset/ethnic-group-population-projections) produced by the Mayor of London. Rates based on residential populations are imperfect because some people being searched in the `r report_bcu` BCU will live in other areas of London or elsewhere, but the local nature of most crime means the majority of people searched in `r report_bcu` BCU are likely to also live there. All ethnicity figures in this report are self-defined ethnicities.

This report is published under a [Creative Commons Attribution Licence version 4.0](https://creativecommons.org/licenses/by/4.0/), meaning you are free to copy or redistribute this material in any medium or format, and to remix, transform, and build upon this material for any purpose, even commercially, as long as you comply with the licence terms.

Cover photo by [Collins Lesulie on Unsplash.com](https://unsplash.com/photos/eBJrKE3gng8)


```{r table-ward}
searches_by_ward %>% 
  filter(bcu == report_bcu) %>% 
  mutate(
    searches = comma(searches, accuracy = 1),
    ward = str_glue("{row_number()}. {ward} ward, {borough}")
  ) %>% 
  select(`council ward` = ward, searches) %>% 
  head(10) %>% 
  knitr::kable(
    format = "latex",
    align = "lr", 
    booktabs = TRUE,
    caption = str_glue("Wards in {report_bcu} BCU with the ",
                       "highest number of searches, {report_period}"),
    linesep = ""
  )
```



\newgeometry{top = 2cm, inner = 1cm, bottom = 3cm, outer = 1cm}

(ref:chart-map) Hotspots of searches, `r report_period`

```{r download-map-tiles, include=FALSE}
map_tiles <- map_area %>% 
  st_transform(4326) %>% 
  st_bbox() %>% 
  set_names(c("left", "bottom", "right", "top")) %>% 
  ggmap::get_stamenmap(maptype = "toner-lite", zoom = 13)
```

```{r chart-map, fig.asp=1, fig.cap="(ref:chart-map)", fig.pos="h", out.width="19cm", message=FALSE, warning=FALSE}
chart_map <- ggmap::ggmap(map_tiles) +
  # KDE layer
  geom_sf(
    aes(fill = kde_value),
    data = st_transform(grid_kde, 4326),
    inherit.aes = FALSE,
    alpha = 0.75,
    colour = NA
  ) +
  # Outlines for boroughs in the report BCU
  geom_sf(
    data = st_transform(filter(london_boroughs, bcu == report_bcu), 4326), 
    inherit.aes = FALSE, 
    colour = ucl_colours_list[["Mid Red"]], 
    fill = NA,
    size = 0.5
  ) +
  # Outline for the report BCU
  geom_sf(
    data = st_transform(filter(london_bcu, bcu == report_bcu), 4326),
    inherit.aes = FALSE,
    colour = ucl_colours_list[["Mid Red"]], 
    fill = NA,
    size = 1
  ) +
  # Borough labels
  geom_sf_text(
    aes(
      label = str_replace_all(str_trim(str_replace_all(
        str_to_upper(str_wrap(str_replace(borough, " and ", " & "), 10)), 
        "(.)", "\\1 ")
      ), " \n", "\n")
    ),
    data = filter(london_boroughs, bcu == report_bcu),
    colour = chart_elements$label_text_colour,
    size = chart_elements$label_text_size,
    lineheight = chart_elements$label_text_lineheight,
    inherit.aes = FALSE,
    check_overlap = TRUE
  ) +
  # Western labels to the left
  ggrepel::geom_label_repel(
    aes(x = coord_x, y = coord_y, label = str_wrap(label, 25)),
    data = filter(hotspot_labels, coord_x < median(coord_x)),
    colour = chart_elements$label_text_colour,
    fill = "white",
    size = chart_elements$label_text_size * 0.8,
    lineheight = chart_elements$label_text_lineheight,
    hjust = 1,
    box.padding = unit(2, "lines"),
    label.padding = unit(0.2, "lines"),
    label.size = NA,
    xlim = c(
      NA, 
      pluck(hotspot_label_lims, "xmin") + ((pluck(hotspot_label_lims, "xmax") - pluck(hotspot_label_lims, "xmin")) / 4)
    ),
    max.iter = 10^5
  ) +
  # Eastern labels to the right
  ggrepel::geom_label_repel(
    aes(x = coord_x, y = coord_y, label = str_wrap(label, 25)),
    data = filter(hotspot_labels, coord_x >= median(coord_x)),
    colour = chart_elements$label_text_colour,
    fill = "white",
    size = chart_elements$label_text_size * 0.8,
    lineheight = chart_elements$label_text_lineheight,
    hjust = 0,
    box.padding = unit(2, "lines"),
    label.padding = unit(0.2, "lines"),
    label.size = NA,
    xlim = c(
      pluck(hotspot_label_lims, "xmax") - ((pluck(hotspot_label_lims, "xmax") - pluck(hotspot_label_lims, "xmin")) / 4),
      NA
    ),
    max.iter = 10^5
  ) +
  coord_sf(
    xlim = c(pluck(st_bbox(map_area), "xmin"), pluck(st_bbox(map_area), "xmax")),
    ylim = c(pluck(st_bbox(map_area), "ymin"), pluck(st_bbox(map_area), "ymax"))
  ) +
  scale_colour_distiller(
    aesthetics = c("colour", "fill"), 
    palette = "Oranges", 
    direction = 1, 
    na.value = "grey90"
  ) +
  theme_stop_search() +
  theme(
    axis.text = element_blank(),
    axis.ticks = element_blank(),
    axis.title = element_blank(),
    legend.position = "none",
    panel.border = element_rect(
      colour = chart_elements$label_line_colour, 
      fill = NA
    ),
    panel.grid = element_blank()
  )

# save_chart(
#   chart_map, 
#   "08_chart_map", 
#   str_glue("Location of searches, {report_period}"),
#   height = 600, 
#   width = 600
# )

chart_map

```



\restoregeometry